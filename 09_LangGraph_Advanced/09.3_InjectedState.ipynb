{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "338a8299",
   "metadata": {},
   "source": [
    "# Injected State\n",
    "\n",
    "While working with [RAGV4](https://github.com/MatteoFalcioni/experiments/blob/main/RAG_V4.0_.ipynb) I noticed a huge problem. \n",
    "\n",
    "I was building an agent supervisor system that managed two worker agents - a data analyst and a visualizer. Problem was, when the data analyst had completed its analysis on the datasets, the visualizer wasn't able to access the analysed data, and he would try to run the analysis again. \n",
    "\n",
    "Why did this happen? Well, the datasets were loaded in memory and stored as global variables in a dictionary. But this made it difficult for different agents to retrieve the same data, as the global needed to be shared and the possibility to access it needed to be enforced through prompting. Isn't there a standard way of letting all agents access the same data at runtime?\n",
    "\n",
    "Of course there is, and it's actually a basic concept in LangGraph: it's the graph's **State**. If we want some object to be accessible and visible to all agents at any time, than that object should be in the Graph state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174a646",
   "metadata": {},
   "source": [
    "So we'd just need to subclass the basic `MessagesState` class from LangGraph and add our relevant object to state to define our *\"state schema\"*, like this: \n",
    "\n",
    "```python\n",
    "class MyState(MessagesState):   # already contains a structure like Annotated[Sequence[BaseMessage], operator.add]\n",
    "    dataframes : dict   # add your needed fields \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffd644",
   "metadata": {},
   "source": [
    "Perfect, right...? No! If we only did this and tried to access the `dataframes` dict inside our tools, we wouldn't manage to do so. \n",
    "\n",
    "We have to follow a specific syntax in order to access state data in our tools and modify it. We need to use the [`InjectedState`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.tool_node.InjectedState) annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377338f7",
   "metadata": {},
   "source": [
    "### Using `InjectedState` in tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6fd210",
   "metadata": {},
   "source": [
    "The following is an example from the [`InjectedState`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.tool_node.InjectedState) documentation.\n",
    "\n",
    "Here they don't subclass `MessagesState` but the principle is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae077438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='not enough messages', name='state_tool', tool_call_id='1'),\n",
       "  ToolMessage(content='bar2', name='foo_tool', tool_call_id='2')]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.prebuilt import InjectedState, ToolNode\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):    # create your state schema\n",
    "    messages: List[BaseMessage]\n",
    "    foo: str\n",
    "\n",
    "@tool\n",
    "def state_tool(x: int, state: Annotated[dict, InjectedState]) -> str:   # use Annotated[dict, InjectedState]\n",
    "    '''Do something with state.'''\n",
    "    if len(state[\"messages\"]) > 2:      # here we use the whole state\n",
    "        return state[\"foo\"] + str(x)\n",
    "    else:\n",
    "        return \"not enough messages\"\n",
    "\n",
    "@tool\n",
    "def foo_tool(x: int, foo: Annotated[str, InjectedState(\"foo\")]) -> str: # we can select a specific field to pass with InjectedState(\"<field_name>\")\n",
    "    '''Do something else with state.'''\n",
    "    return foo + str(x + 1)\n",
    "\n",
    "node = ToolNode([state_tool, foo_tool])\n",
    "\n",
    "tool_call1 = {\"name\": \"state_tool\", \"args\": {\"x\": 1}, \"id\": \"1\", \"type\": \"tool_call\"}\n",
    "tool_call2 = {\"name\": \"foo_tool\", \"args\": {\"x\": 1}, \"id\": \"2\", \"type\": \"tool_call\"}\n",
    "state = {\n",
    "    \"messages\": [AIMessage(\"\", tool_calls=[tool_call1, tool_call2])],\n",
    "    \"foo\": \"bar\",\n",
    "}\n",
    "node.invoke(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786f50f",
   "metadata": {},
   "source": [
    "### Integrating `InjectedState` with agents\n",
    "\n",
    "The simplest way to integrate `InjectedState` with agentic framework is to use the [`create_react_agent()`](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent) function from LangGraph. \n",
    "\n",
    "We need to pass our custom state as the `state_schema` parameter, like this:\n",
    "\n",
    "```python\n",
    "agent = create_react_agent(\n",
    "    model=..., \n",
    "    tools=[state_tool, foo_tool],\n",
    "    state_schema=MyState\n",
    ")\n",
    "```\n",
    "\n",
    "In this way the model knows what states it's working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ba594",
   "metadata": {},
   "source": [
    "### Other Context Management practises \n",
    "\n",
    "Before moving to a practical example, allow us to cite [other common context management practises in LangGraph](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#context-management).\n",
    "\n",
    "As a matter of fact, `InjectedState` is not the only way to allow our graph state to persist as context data. It is the most flexible and \"lightweight\" standard, but we can use: \n",
    "\n",
    "* [`Configuration`](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#configuration) : \"*Use configuration when you have static, immutable runtime data that tools require, such as user identifiers\"*. \n",
    "\n",
    "* [Long term memory](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#long-term-memory) : *\"Use long-term memory to store user-specific or application-specific data across different sessions\"*. The main difference here is that the data persists to other sources (like disk) even after the current session ends. This is useful for working with heavy datasets, or to leverage memory across different runs of a chatbot. See [Stores](https://langchain-ai.github.io/langgraph/reference/store/#storage) for further references."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250c1b4",
   "metadata": {},
   "source": [
    "## Example #1 of `InjectedState` workflow\n",
    "\n",
    "Let's make a simple example to recap the actual workflow with `InjectedState`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3359cec",
   "metadata": {},
   "source": [
    "### 1. Create your custom \"`state_schema`\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b97a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class CustomState(MessagesState): \n",
    "    username : str \n",
    "    remaining_steps : int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b86d3b",
   "metadata": {},
   "source": [
    ">**Note:** from the [create_react_agent() doc](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent):  \n",
    ">\n",
    ">*`state_schema` : An optional state schema that defines graph state. Must have `messages` and `remaining_steps` keys. Defaults to AgentState that defines those two keys.*\n",
    ">\n",
    "> `messages` is implemented by `MessagesState`, but we need to implement `reamining_steps` otherwise it will error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6c77a",
   "metadata": {},
   "source": [
    "### 2. Write your tools using `InjectedState`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb4b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.types import Command\n",
    "\n",
    "@tool \n",
    "def get_internal_value(state : Annotated[CustomState, InjectedState]) -> str:\n",
    "    \"\"\"tool to retrieve the username\"\"\"\n",
    "    return state.get('username')\n",
    "\n",
    "@tool \n",
    "def update_username(new_name : str, tool_call_id : Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"Update username in short-term memory.\"\"\"\n",
    "    \n",
    "    return Command(update={\n",
    "        \"username\" : new_name,\n",
    "        \"messages\" : [\n",
    "            ToolMessage(f\"Updated username to {new_name}\", tool_call_id=tool_call_id)\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b909be",
   "metadata": {},
   "source": [
    ">**Note:** Notice how we used: \n",
    ">   - `state.get()` to read the value\n",
    ">   - a `Command` return in order to update the state : here we also need to append to messages a `ToolMessage`, otherwise it will error. In order to do so, we constructed it with `Annotated[str, InjectedToolCallId]` to follow the correct approach - but we could have done it in a simpler way like `ToolMessage(\"Success\", tool_call_id=...)` as the error suggests:\n",
    ">\n",
    ">   *Expected to have a matching ToolMessage in Command.update for tool 'update_username', got: []. Every tool call (LLM requesting to call a tool) in the message history MUST have a corresponding ToolMessage. You can fix it by modifying the tool to return `Command(update=[ToolMessage(\"Success\", tool_call_id=tool_call_id), ...], ...)`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be688d3a",
   "metadata": {},
   "source": [
    "### 3. Create the agent passing the custom `state_schema` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84897c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    tools=[update_username, get_internal_value],\n",
    "    state_schema=CustomState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6050f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your previous username was \"Matteo.\" It has been updated to \"Mario.\" Now, your username is \"Mario.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Whats my username? Update it to Mario. What's the username now?\")],\n",
    "    \"username\": \"Matteo\",\n",
    "    \"remaining_steps\": 15\n",
    "}\n",
    "\n",
    "print(agent.invoke(initial_state)[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebf364",
   "metadata": {},
   "source": [
    "## RAGV4 Example\n",
    "\n",
    "How about a practical application? \n",
    "\n",
    "Let's correctly build RAGV4 using `InjectedState`. We will only build the data analyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b2f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
