{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcb19c5",
   "metadata": {},
   "source": [
    "# Recursion Limits\n",
    "\n",
    "In this notebook let's make some tries defining `remaining_steps` inside a custom `state_schema` and seeing if it works for recursion limit control. \n",
    "\n",
    "Then after that try and set explicit control flows. I know how to do it in a `Command[Literal[\"next_possible_node1\", \"next_possible_node2\"]]` fashion, can I use that? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d36d3c",
   "metadata": {},
   "source": [
    "> Here are some sources for this topic:\n",
    "> - [Graph-API: Impose a recursion limit](https://langchain-ai.github.io/langgraph/how-tos/graph-api/?utm_source=chatgpt.com#impose-a-recursion-limit);\n",
    "> - ['Medium' post about recursion limits](https://medium.com/@pankajchandravanshi/df371792c8b9);\n",
    "> - [Adding `remaining_steps` fixed a recursion error problem](https://stackoverflow.com/questions/79446089/langgraph-create-react-agent-with-sqltoolkit-issue-sorry-need-more-steps-to-pr?utm_source=chatgpt.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54d99a",
   "metadata": {},
   "source": [
    "### Custom state schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60e2dd",
   "metadata": {},
   "source": [
    "Let's make a very simple example: a custom state with a counter that we increment by $1$ at every step (basically the step counter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e778ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# reducer\n",
    "def counter_add(current_value: int, value_to_add: int):\n",
    "    return current_value + value_to_add\n",
    "\n",
    "# custom state\n",
    "class CustomState(MessagesState):\n",
    "    counter: Annotated[int, counter_add]  \n",
    "    remaining_steps: int "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7821e98",
   "metadata": {},
   "source": [
    "Also, let's make another state schema for experiments where we use the `RemainingSteps` marker from `langgraph.managed.is_last_step`. LangGraph should recognize this type and manage it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb875d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "class RemainingStepsState(MessagesState):\n",
    "    counter: Annotated[int, counter_add] # = 8 setting defaults here won't work \n",
    "    remaining_steps: RemainingSteps # = 5 defaults need to be set in graph's initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e057b4c",
   "metadata": {},
   "source": [
    ">**Note:** LangGraph does not support default values defined inside your state class (especially with annotated or reduced fields). Always provide defaults at runtime via an `initial_state` (see below). \n",
    ">\n",
    "> *Don’t assign a default inside the class definition or via annotation—LangGraph will ignore it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a998f2",
   "metadata": {},
   "source": [
    "### Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d7de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for printing\n",
    "\n",
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "\n",
    "def pretty_print_message(message, indent=False):\n",
    "    pretty_message = message.pretty_repr(html=True)\n",
    "    if not indent:\n",
    "        print(pretty_message)\n",
    "        return\n",
    "\n",
    "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
    "    print(indented)\n",
    "\n",
    "\n",
    "def pretty_print_messages(update, last_message=False):\n",
    "    is_subgraph = False\n",
    "    if isinstance(update, tuple):\n",
    "        ns, update = update\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "\n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}:\")\n",
    "        print(\"\\n\")\n",
    "        is_subgraph = True\n",
    "\n",
    "    for node_name, node_update in update.items():\n",
    "        update_label = f\"Update from node {node_name}:\"\n",
    "        if is_subgraph:\n",
    "            update_label = \"\\t\" + update_label\n",
    "\n",
    "        print(update_label)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        messages = convert_to_messages(node_update[\"messages\"])\n",
    "        if last_message:\n",
    "            messages = messages[-1:]\n",
    "\n",
    "        for m in messages:\n",
    "            pretty_print_message(m, indent=is_subgraph)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904e19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_counter(\n",
    "    state: Annotated[CustomState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"Updates the internal counter, incrementing it by 1\"\"\"\n",
    "    return Command(\n",
    "        update={\n",
    "            \"counter\": 1,\n",
    "            \"messages\": [ToolMessage(content=\"Counter updated\", tool_call_id=tool_call_id)]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def check_counter_value(state: Annotated[CustomState, InjectedState],\n",
    "                        tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"Checks the value of the counter\"\"\"\n",
    "\n",
    "    counter = state.get(\"counter\")\n",
    "    remaining_steps = state.get(\"remaining_steps\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\" : [ToolMessage(content=f\"Counter value: {counter}\\nRemaining steps: {remaining_steps}, type:{type(remaining_steps)}\", tool_call_id=tool_call_id)]\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53762fa2",
   "metadata": {},
   "source": [
    "#### Create two agents with the two custom states for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a321131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[update_counter, check_counter_value],\n",
    "    prompt=\"You are an helpful AI assistant.\",\n",
    "    name=\"counter_agent\",\n",
    "    state_schema=CustomState\n",
    ")\n",
    "\n",
    "agent_RemainingSteps = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[update_counter, check_counter_value],\n",
    "    prompt=\"You are an helpful AI assistant.\",\n",
    "    name=\"counter_agent\",\n",
    "    state_schema=RemainingStepsState\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a2f25",
   "metadata": {},
   "source": [
    "### Experiments with `remaining_steps` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94276f0",
   "metadata": {},
   "source": [
    "#### Using `RemainingSteps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e19427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_zfiQ0YS8az49Lovm89lo19qm)\n",
      " Call ID: call_zfiQ0YS8az49Lovm89lo19qm\n",
      "  Args:\n",
      "  update_counter (call_H6heq7lX3fgxWNkzMcKGH9Cp)\n",
      " Call ID: call_H6heq7lX3fgxWNkzMcKGH9Cp\n",
      "  Args:\n",
      "  update_counter (call_fqRzIxz1w1CXuuN0D34zNAKD)\n",
      " Call ID: call_fqRzIxz1w1CXuuN0D34zNAKD\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  check_counter_value (call_cWKtHFUBY2sg4e164UyLe3rw)\n",
      " Call ID: call_cWKtHFUBY2sg4e164UyLe3rw\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_counter_value\n",
      "\n",
      "Counter value: 3\n",
      "Remaining steps: 22, type:<class 'int'>\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "\n",
      "The counter has been updated 3 times, and its current value is 3.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 3 times and then check its value\")],\n",
    "}\n",
    "\n",
    "for chunk in agent_RemainingSteps.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ecb3c",
   "metadata": {},
   "source": [
    "Without providing defaults in the initial state, LangGraph automatically initializes `remaining_steps` to $25$, since we defined it through `RemainingSteps`. Also the `counter` is initialized to $0$ as that's the default for `int` type in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "046e0456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_hmuf5cDnssHpX5DVCpNLLp9P)\n",
      " Call ID: call_hmuf5cDnssHpX5DVCpNLLp9P\n",
      "  Args:\n",
      "  update_counter (call_93IaF7GJDVEbLy8A0Z1zWFno)\n",
      " Call ID: call_93IaF7GJDVEbLy8A0Z1zWFno\n",
      "  Args:\n",
      "  update_counter (call_U8aysDZbaY8oCM9jIYD6n0TG)\n",
      " Call ID: call_U8aysDZbaY8oCM9jIYD6n0TG\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  check_counter_value (call_zsjnKNBjcz1zdJn5BRgXRShY)\n",
      " Call ID: call_zsjnKNBjcz1zdJn5BRgXRShY\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_counter_value\n",
      "\n",
      "Counter value: 3\n",
      "Remaining steps: 22, type:<class 'int'>\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "\n",
      "The counter has been updated 3 times, and its current value is 3.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying to initialize RemainingSteps to a custom value\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 3 times and then check its value\")],\n",
    "    \"counter\": 0,\n",
    "    \"remaining_steps\": 3    # this doesn't work\n",
    "}\n",
    "\n",
    "for chunk in agent_RemainingSteps.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ed5947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_5vcwkO4jsLFX1AnogWUrehR5)\n",
      " Call ID: call_5vcwkO4jsLFX1AnogWUrehR5\n",
      "  Args:\n",
      "  update_counter (call_yCSTnCQNUK0a2EH9OuvgvcDg)\n",
      " Call ID: call_yCSTnCQNUK0a2EH9OuvgvcDg\n",
      "  Args:\n",
      "  update_counter (call_8Kiiyxvyg4UUt2n5XzWaBpfp)\n",
      " Call ID: call_8Kiiyxvyg4UUt2n5XzWaBpfp\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  check_counter_value (call_po2PNEKBUjGksBJGGgFjGIlv)\n",
      " Call ID: call_po2PNEKBUjGksBJGGgFjGIlv\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_counter_value\n",
      "\n",
      "Counter value: 3\n",
      "Remaining steps: 22, type:<class 'int'>\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "\n",
      "The counter has been updated 3 times, and its current value is 3.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 3 times and then check its value\")],\n",
    "    \"counter\": 0,\n",
    "    \"remaining_steps\": RemainingSteps(3)    # this doesn't work\n",
    "}\n",
    "\n",
    "for chunk in agent_RemainingSteps.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667636b",
   "metadata": {},
   "source": [
    "#### Tries *without* the `RemainingSteps` marker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f73ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_GdUV3F4mt04zq2P2f0VDCLCw)\n",
      " Call ID: call_GdUV3F4mt04zq2P2f0VDCLCw\n",
      "  Args:\n",
      "  update_counter (call_4CEISA5HUhDxfUdVA5KtQFp4)\n",
      " Call ID: call_4CEISA5HUhDxfUdVA5KtQFp4\n",
      "  Args:\n",
      "  update_counter (call_mU9pB3Nvl5VUJHejLJZe8mTO)\n",
      " Call ID: call_mU9pB3Nvl5VUJHejLJZe8mTO\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_Wz7f5q2hKLk9KuNIrgCC4Om3)\n",
      " Call ID: call_Wz7f5q2hKLk9KuNIrgCC4Om3\n",
      "  Args:\n",
      "  update_counter (call_SHAkfh6hRKgAe3K5Mn6oiu5k)\n",
      " Call ID: call_SHAkfh6hRKgAe3K5Mn6oiu5k\n",
      "  Args:\n",
      "  update_counter (call_rhAYQpfjW20M1LiSCkaV9oeo)\n",
      " Call ID: call_rhAYQpfjW20M1LiSCkaV9oeo\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_kxzcBX5Kf4rx2pJTsWhmrjWV)\n",
      " Call ID: call_kxzcBX5Kf4rx2pJTsWhmrjWV\n",
      "  Args:\n",
      "  update_counter (call_VElUwu45OEYJQHXLElQSShVk)\n",
      " Call ID: call_VElUwu45OEYJQHXLElQSShVk\n",
      "  Args:\n",
      "  update_counter (call_joehmnpHQI8SE8179mTJYmTI)\n",
      " Call ID: call_joehmnpHQI8SE8179mTJYmTI\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Error: 1 validation error for update_counter\n",
      "state.remaining_steps\n",
      "  Field required [type=missing, input_value={'messages': [HumanMessag...g': 0}})], 'counter': 0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      " Please fix your mistakes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[1;32m      4\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdate your counter 3 times and then check its value\u001b[39m\u001b[38;5;124m\"\u001b[39m)],\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mstream(initial_state):\n\u001b[1;32m      9\u001b[0m     pretty_print_messages(chunk)\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2534\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2533\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2535\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2536\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2537\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2538\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2539\u001b[0m ):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2542\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2543\u001b[0m     )\n\u001b[1;32m   2544\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langgraph/pregel/runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langgraph/pregel/retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langgraph/utils/runnable.py:370\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 370\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    372\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langgraph/prebuilt/chat_agent_executor.py:507\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StateSchema:\n\u001b[1;32m    506\u001b[0m     state \u001b[38;5;241m=\u001b[39m _get_model_input_state(state)\n\u001b[0;32m--> 507\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_core/runnables/base.py:3046\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3045\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3046\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_core/runnables/base.py:5434\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5427\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5429\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5432\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5433\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5435\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 395\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:980\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    978\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    979\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:799\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 799\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m         )\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1045\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1045\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1130\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1237\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1246\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1247\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1248\u001b[0m     )\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:972\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    978\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 3 times and then check its value\")],\n",
    "}\n",
    "\n",
    "for chunk in agent.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f03f2d",
   "metadata": {},
   "source": [
    "Interestingly, if we do not use RemainingSteps and initialize with an int we **must** pass an initial state for `remaining_steps`. Notice instead that LangGraph is more flexible about other custom variables, so  even if we don't initialize `counter`, it is set to $0$ anyway by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18665033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sorry, need more steps to process this request.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 3 times and then check its value\")],\n",
    "    \"remaining_steps\" : 1\n",
    "}\n",
    "\n",
    "for chunk in agent.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b3421",
   "metadata": {},
   "source": [
    "As we can see, passing a value of $1$ (or even $0$) halts the workflow: so LangGraph seems to automatically check the value of `remaining_steps` even if it's not initialized through `RemainingSteps`. But if we do not implement a custom reducer, the graph won't know how to handle it -> it won't be decrementing `remaining_steps`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c096c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter (call_kzSTZCTzCotedeq9QeNr0531)\n",
      " Call ID: call_kzSTZCTzCotedeq9QeNr0531\n",
      "  Args:\n",
      "  update_counter (call_M6yBCVFzYef0kTLrKvVod4jr)\n",
      " Call ID: call_M6yBCVFzYef0kTLrKvVod4jr\n",
      "  Args:\n",
      "  update_counter (call_lxw7c2iQ1SXB0KuqGzTGlZD8)\n",
      " Call ID: call_lxw7c2iQ1SXB0KuqGzTGlZD8\n",
      "  Args:\n",
      "  update_counter (call_0MxnHqpOkhBADLSQo5WcgXZf)\n",
      " Call ID: call_0MxnHqpOkhBADLSQo5WcgXZf\n",
      "  Args:\n",
      "  update_counter (call_jDmjOMsA8pPsKJ9cilc9JZZP)\n",
      " Call ID: call_jDmjOMsA8pPsKJ9cilc9JZZP\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  check_counter_value (call_UiWbhJsgaBdEsETm6M9l61uv)\n",
      " Call ID: call_UiWbhJsgaBdEsETm6M9l61uv\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_counter_value\n",
      "\n",
      "Counter value: 5\n",
      "Remaining steps: 2, type:<class 'int'>\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "\n",
      "The counter has been updated 5 times, and its current value is 5.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 5 times and then check its value\")],\n",
    "    \"remaining_steps\" : 2\n",
    "}\n",
    "\n",
    "for chunk in agent.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4589fa",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "* if we initialize it as `RemainingSteps`, LangGraph handles it automatically. BUT we have no control over its default;\n",
    "* if we initialize it as an `int`:\n",
    "\n",
    "  * LangGraph checks by default its value to halt the workflow if it's $0$;\n",
    "  * we can set the default in the `initial_state` and pass it to `.stream`;\n",
    "  * we need to assign it a reducer that decrements it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2456bd0",
   "metadata": {},
   "source": [
    "Notice that another way to set the recursion limit is by using graph configuration keys. We can do that passing `config` to `.stream` or when we initialize the agent: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ed9f6",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# agent\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "recursion_limit = 3\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[update_counter, check_counter_value],\n",
    "    prompt=\"You are an helpful AI assistant.\",\n",
    "    name=\"counter_agent\",\n",
    "    state_schema=CustomState\n",
    ").with_config(recursion_limit=recursion_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570cef43",
   "metadata": {},
   "source": [
    "### Implement a reducer for `remaining_steps: int`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f020b",
   "metadata": {},
   "source": [
    "Let's check what happens if we initialize it as an `int` and implement a custom reducer: will the workflow automatically halt when we reach $0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea6142",
   "metadata": {},
   "source": [
    "We can actually use `counter_add` but tell the tools to update `remaining_steps` with `-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf28d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom state\n",
    "class NewCustomState(MessagesState):\n",
    "    counter: Annotated[int, counter_add]  \n",
    "    remaining_steps: Annotated[int, counter_add]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7041a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_counter_new(\n",
    "    state: Annotated[NewCustomState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"Updates the internal counter, incrementing it by 1\"\"\"\n",
    "    return Command(\n",
    "        update={\n",
    "            \"counter\": 1,\n",
    "            \"remaining_steps\" : -1,\n",
    "            \"messages\": [ToolMessage(content=\"Counter updated\", tool_call_id=tool_call_id)]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def check_counter_value_new(state: Annotated[NewCustomState, InjectedState],\n",
    "                        tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> Command:\n",
    "    \"\"\"Checks the value of the counter\"\"\"\n",
    "\n",
    "    counter = state.get(\"counter\")\n",
    "    remaining_steps = state.get(\"remaining_steps\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\" : [ToolMessage(content=f\"Counter value: {counter}\\nRemaining steps: {remaining_steps}, type:{type(remaining_steps)}\", tool_call_id=tool_call_id)],\n",
    "            \"remaining_steps\" : -1\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10111fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[update_counter_new, check_counter_value_new],\n",
    "    prompt=\"You are an helpful AI assistant.\",\n",
    "    name=\"counter_agent\",\n",
    "    state_schema=NewCustomState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cdb08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  update_counter_new (call_9xxEVzMqH8mHLM66YKnc9sZ2)\n",
      " Call ID: call_9xxEVzMqH8mHLM66YKnc9sZ2\n",
      "  Args:\n",
      "  update_counter_new (call_9QgdASArpZDAgbhxeB8kvsg8)\n",
      " Call ID: call_9QgdASArpZDAgbhxeB8kvsg8\n",
      "  Args:\n",
      "  update_counter_new (call_JRR5pswUK1bfOdDPeUxoLMgO)\n",
      " Call ID: call_JRR5pswUK1bfOdDPeUxoLMgO\n",
      "  Args:\n",
      "  update_counter_new (call_ERcppFLcH9uGoD3609AwhFBP)\n",
      " Call ID: call_ERcppFLcH9uGoD3609AwhFBP\n",
      "  Args:\n",
      "  update_counter_new (call_TNUi0d92aCZkWWpJT6OAcx9B)\n",
      " Call ID: call_TNUi0d92aCZkWWpJT6OAcx9B\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sorry, need more steps to process this request.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Update your counter 5 times and then check its value\")],\n",
    "    \"remaining_steps\" : 2\n",
    "}\n",
    "\n",
    "for chunk in agent.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70216e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  check_counter_value_new (call_BtdQ07WFA3ZMnf18vdIpOS22)\n",
      " Call ID: call_BtdQ07WFA3ZMnf18vdIpOS22\n",
      "  Args:\n",
      "  update_counter_new (call_7CvEn3PJPjM6OkmICCJEyqe2)\n",
      " Call ID: call_7CvEn3PJPjM6OkmICCJEyqe2\n",
      "  Args:\n",
      "  update_counter_new (call_XAfNYWGwWddWFoBHcpNSF8nU)\n",
      " Call ID: call_XAfNYWGwWddWFoBHcpNSF8nU\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_counter_value_new\n",
      "\n",
      "Counter value: 0\n",
      "Remaining steps: 5, type:<class 'int'>\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: counter_agent\n",
      "Tool Calls:\n",
      "  check_counter_value_new (call_jSgcoq0MGpwVB84xlIljTNTC)\n",
      " Call ID: call_jSgcoq0MGpwVB84xlIljTNTC\n",
      "  Args:\n",
      "  update_counter_new (call_fDntkjCWYiNUlYSL1ASxDyso)\n",
      " Call ID: call_fDntkjCWYiNUlYSL1ASxDyso\n",
      "  Args:\n",
      "  update_counter_new (call_4uqDnGuTv4PNJrk9GbY9BEjV)\n",
      " Call ID: call_4uqDnGuTv4PNJrk9GbY9BEjV\n",
      "  Args:\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_counter_value_new\n",
      "\n",
      "Counter value: 2\n",
      "Remaining steps: 2, type:<class 'int'>\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node tools:\n",
      "\n",
      "\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_counter_new\n",
      "\n",
      "Counter updated\n",
      "\n",
      "\n",
      "Update from node agent:\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sorry, need more steps to process this request.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"Check your counter value, then update it twice, then check its value again, then update it two more times\")],\n",
    "    \"remaining_steps\" : 5\n",
    "}\n",
    "\n",
    "for chunk in agent.stream(initial_state):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8646ea",
   "metadata": {},
   "source": [
    "It works! **The workflow was automatically halted by LangGraph internal checks**. \n",
    "\n",
    "So, to resume, the most controlled way to work with remaining steps is to initialize it as an `int` in your custom state schema and add a reducer to decrement it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1fc0d",
   "metadata": {},
   "source": [
    "### Custom flow halting controls \n",
    "\n",
    "In order to have even more control on flow halting, we could check through `InjectedState` and eventually halt with a `Command[Literal[END]]` return.\n",
    "\n",
    "Now, I tried to do this but I saw that just using `Command[Literal[END]]` as a return doesn't actually halt the workflow! \n",
    "\n",
    "Instead, it just tells the graph to go to the next node he would process - so he keeps trying to access the stopped node until the llm understands it must stop. \n",
    "\n",
    "A fix to this is to use a more controlled flow, in the sense of the `multi_agent_colaboration` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e15c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langgraph.graph import END\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "updater_agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[update_counter_new],\n",
    "    prompt=\"You are an helpful AI assistant.\",\n",
    "    name=\"updater_agent\",\n",
    "    state_schema=NewCustomState\n",
    ")\n",
    "\n",
    "def update_node(state: Annotated[NewCustomState, InjectedState])-> Command[Literal[\"should_continue\"]]:\n",
    "    \n",
    "    chat_history = state.get(\"messages\")\n",
    "    remaining_steps = state.get(\"remaining_steps\")\n",
    "    \n",
    "    result = updater_agent.invoke({\"messages\": chat_history, \"remaining_steps\": remaining_steps})\n",
    "    \n",
    "    return Command(\n",
    "        update={\"counter\": 1, \"remaining_steps\": -1, \"messages\": result[\"messages\"]},\n",
    "        goto=\"should_continue\"\n",
    "    )\n",
    "\n",
    "\n",
    "# router\n",
    "def should_continue(state: Annotated[NewCustomState, InjectedState]\n",
    ") -> Command[Literal[\"update_node\", END]]:\n",
    "    \n",
    "    if state[\"remaining_steps\"] <= 3:\n",
    "\n",
    "        return Command(\n",
    "            update=\n",
    "            {\n",
    "                \"messages\": \n",
    "                [\n",
    "                    AIMessage(content=\"Stop condition met!\")\n",
    "                ]\n",
    "            }, \n",
    "            goto=END\n",
    "        )\n",
    "    \n",
    "    return Command(\n",
    "            update=\n",
    "            {\n",
    "                \"messages\": \n",
    "                [\n",
    "                    AIMessage(content=\"Continue the workflow\")\n",
    "                ]\n",
    "            }, \n",
    "            goto=\"update_node\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0055998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "builder = StateGraph(NewCustomState)\n",
    "builder.add_node(\"should_continue\", should_continue)\n",
    "builder.add_node(\"update_node\", update_node)\n",
    "builder.add_edge(START, \"should_continue\")\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43bd02ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD5CAIAAACLY0a/AAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU1f/B/CTHTLZewsiSHGAwuNAEBG3Yh1FcdDWqnW0VhwdWufPKo6ntdXaSq2tgnVVRNwDF7geBQRxIHsTVshObvL7IxaohnVJuDfJeb/8A3KTe7+GfHLOueNcgkqlAhAEdRER6wIgSC/B5EAQGjA5EIQGTA4EoQGTA0FowORAEBpkrAvQb031ikaeXMhXCPkKRKZSKrEuqBOodCKdSWRyyGwzspkNFety9BUBHs9BgVcme/1UUJAtoDPJQKVicskMDonOICkR/XgzG2vlIj5CMyFWFUvcfFnuvkwHDxOsi9IzMDld01SvSEvmEUgEUyuKe1+mpQMN64q6hV8rL8gR1lXI6mpkQydY2rrSsa5Ib8DkdMHDS3XPHvCHTLD0HMDCuhYtK8+XpCXzrBxpI963wroW/QCT01ln9pV5BXC8B7OxLkSHil+Irx2rnLXKhcaAu446AJPTKb99WzA62tbR0/AHA8JGRcKO4pj1bmQaAetacA0mp2Px6wsilzia21CwLqTnHFxXMGu1M4NNwroQ/IKNcgfO7C+LmGNrVLEBAMxe45wYV4x1FbgG25z2PLxcx+JSvAMNeWzTlvJ8yfNH/JEzrLEuBKdgm9MmQYMiO51vnLEBANi704WNiqJcEdaF4BRMTpvSztUOmWCBdRVYGjLBMu0cD+sqcAomR7O6KplKqfLyN9IGR83CjurSh/k6U4B1IXgEk6PZ6ywB16qn9wqMGjWqrKysq6/Ky8ubMGGCbioCNi60l0+adLRyvQaTo1lBttC9b4+eKFBaWtrQ0IDihdnZ2Too5w23vqyCbKHu1q+/4LnSGggbECqdaO2sk3PSVCpVQkJCSkpKcXGxm5tbYGDg4sWLHz58uHTpUgDA5MmTR4wYsWvXrtevX588efLBgweVlZVubm7vv/9+ZGSkeg0hISGLFi26du3akydPZs2alZCQAAAICAhYsWLF7NmztVstkQT6DOaUPBc79TH8o8Bdo4LeUZonOvVjqY5WnpCQMHTo0OTkZB6Pd/r06bCwsMOHD6tUqtu3b/v7+5eWvtnuwoULIyMjHz16VFdXd+LECX9///T0dPWi8PDwyZMnx8XF3bt3Ty6Xf//99+PHj9dRtSqV6tbfNRk363W3fj0F2xwNRHyEydHV4fPHjx/7+/urRyaRkZEBAQESieTdp23fvl0kEtnZ2QEApk2b9vfff6elpQUFBQEASCSStbV1bGysjip8C4NNEvKRntmWHoHJ0UDIVzA5unpn+vXrt3fv3k2bNgUHB/v7+zs5OWl8mlKpPHr0aFpaWnHxm2P5bm5uzUu9vb11VN67mBxyfRU8qvM2mByNCGSyrvadREVFMRiMW7duxcbGksnkiIiIZcuWWVpatn4OgiDLli1TqVTLli0LCAhgs9nz589v/QQqteeu5SSRCQQiPPvzbTA5GpiwiNUlGnpQWkEikaZOnTp16tT8/Pz79+8fOHBAKBTu3Lmz9XOePXv2/Pnz/fv3Dxo0SP1IUxNmu4YFDQo6vOjgHTA5GjA5ZBFfoYs1q1SqlJQUHx8f9380NjaeO3furaepd09bWb25yCwvL6+oqKgne2itCfkKFhd+Tt4Gv0s0YJuRqSY62UNAIBDOnTu3evXq27dv8/n8O3fupKam+vn5AQBcXV0BAFevXs3Ozu7VqxeBQDh69KhAICgoKNi9e3dQUFBFRYXGdTo7O/N4vJs3bxYVFemiZqACpj1+UBj/YHI04FpSGmpkdZUyXax8w4YNrq6uK1asGDly5JYtW0JDQ7/++msAgKOj48SJE/fv37937157e/stW7ZkZGSEhISsXLlyyZIl06ZNy8zMnDlz5rsrHDZsWP/+/VeuXHnp0iVdFJx5p8HZm6mLNes1eJWBZukptVQa0X+UGdaFYKwoV5R1u2HiJ/ZYF4I7sM3RrJcfq75aJ22OfqkqlngONOrTXtsCR36aWTvRxEKkKFfk4s3Q+ISamprp06drXMThcPh8vsZFHh4eBw8e1GqlLf7888/4+HiNi0gkEoJoPpoZGxvb1gmjwkZFzr3GmG/dNC41crC31qbaCtnlI5VRq5w1LlUoFNXV1RoXSaVSGk3zOW8UCqV5j5nWNTU1tbXzuqmpic3W3HRwuVwmU/Mw5vKRKhdvhpFfatEW2Oa0ycKO6uzFKMgWuvlq+GCRyWR7e3z1/tlsdlvxQKG+Sg6vUGoHHOe0Z+gky7RzvPoqYxzwJMQVhUfbYl0FfsHkdGDWapeEHUY3C0zijpIZnzsR4aejbXCc0zElovrl64JZq5w4FkZxQDAxrnjSAnumKezJtwcmp1MUclXC9qLQ6dZOXpp3tRmGuip5YlzRjBVOVno+03wPgMnpgpuna2orZEMnWNi4GNqc/4IGxd1knkoFRkfbwk5aZ8DkdE3Za3FaMs/W1cTKgebmy6SZ6PenTKUCBTnC6mLp80f8IRMsesODnp0Gk4NG4TNRXkZTfrbQ1YdJIhOYXBKTQ6YxSCqlHryZSkTVVK8Q8hVEEuHp3Ua3vkzPfuze/oZ2XxNdg8nplvICSUO1TMhXiPgIogCIQpu3OywvLxcKhZ6enlpcJwCAZkKiM4gMDoljTnHuY8jDNp2C+0+6xd6Nbu+mqzHPqVN3yl++DJ89TEfrh7pDv7vpEIQVmBwIQgMmB4LQgMmBIDRgciAIDZgcCEIDJgeC0IDJgSA0YHIgCA2YHAhCAyYHgtCAyYEgNGByIAgNmBwIQgMmB4LQgMmBIDRgciAIDZgcCEIDJgeC0IDJgSA0YHIgCA2YHAhCAyYHgtCAycEvMplMpxvaBNYGAyYHvxQKhUQiwboKSDOYHAhCAyYHgtCAyYEgNGByIAgNmBwIQgMmB4LQgMmBIDRgciAIDZgcCEIDJgeC0IDJgSA0YHIgCA2YHAhCAyYHgtCAyYEgNAgqlQrrGqB/GTNmTHV1NYHQ8qdR//z48WOsS4NawDYHd8LCwlQqFYFAIP4DABAYGIh1XdC/wOTgzowZM1xdXVs/wuVyo6KisKsI0gAmB3dcXFwGDx7c+hFPT8/g4GDsKoI0gMnBo1mzZjk6Oqp/5nK50dHRWFcEvQ0mB49cXFyCgoLUP/fq1Wv48OFYVwS9DSYHp2bOnOno6AgbHNwiY12ANjXUyGvKpGKBAutCtMIsyGdGVVWVKdEv604D1sVoAd2EbG5HtbSnYl2IdhjI8RxEoToXX9HIk9u4mJDIBKzLgTQgU4hleUITJmnkTGtTKwrW5XSXISRHJlEl/VzWL8TCzs0E61qgDoj4itQTlRFzbU0t9bu/YwjjnL/3lQaMtoKx0QsMDnnMfIeE7YVYF9Jdep+cgmyhqRXN0oGGdSFQZxFJhAGhFo+u1mNdSLfofXKqS6UMjn63+0aIY0GtKtLvKbP1PjlSEcLm6v1w09gwTckSsRLrKrpF75OjUKgQ/d/JYWxUSiCXwuRAkPGByYEgNGByIAgNmBwIQgMmB4LQgMmBIDRgciAIDZgcCEIDJgeC0IDJgSA0YHIgCA2YnBbTZ449GP+TttZ26vSxUaM1Ty+4a/fWjz/Bcv60iZNDjiYcwrAAAwCTYyw2bFxz/kKS+ucPZs57z7c/xgXpOZgcY/H8RU7zz7Nnxfj5DcC0HL1njMkpLMzfsHHN5MiwqdNGr1sfm52d2byITKacPn0sPCJowqQRa7/6rJHfqH68orJ8w8Y102aMiRg7ZOGi6ITE39WP5+RkhYYF5D5v+VB+MGvCgV9+eGuLIpHo63VfjJswfMmymCtXL3SyTgRBEhJ/HzNu6Njxw1bGLm6us61i8vJehoYFPHx075v1K0PDAmZGjf/5wPcqlUqhUISGBVRVVcbt3Dxxckjr3lpbLwEAHE04NHb8sOZiyivKQsMC7t27o/716dOM2FWfTpwUMi9m2v6f/ysUCrv+d9BvRpccmUz2RewiBEH27Dqw/bu9RCLx63VfSKVS9dIbqZeFIuGO7T+uil2fnZ1x6NB+AIBSqYxd9WkNr3rrlj3Hj50fNiz014M/pt682vmN7ty1ubS0eGfc/s0bd+blvXj4KL0zrzrwyw/Jyac2b9r1zVdbLa2s1361vLS0uJ1iqFQqAGDX7i2jwsZevpi+ds3Gv47/eSP1CplMvnj+LgBgVey65KTU1pto6yXtF1ZcXLh67VK5Qv7Tj79/u+67V6+er4xdpFTq9/U2XWV01yGXlBTV19dFRc13d/cAAKxfty3r6ROFQkGj0QAALBZ7TvRH6mfeTbuZ9fQJAOD+/bvl5aXbtv7X2dkVADAn+qOHj9IvXDwbMmJUZ7bI49XcSL2yZvW3Pt6+AIBFCz9LS7/V4asaGupPnDz6+WdrBwUEAQACA4eKhEIer6akpKitYtR3PRg/LlJd2ID+ATY2ts+f54wMHd3WVlC8BABw9doFCpmyaUMcl2sKAFi1av2s2ZPS0m8NGxrSmTfEMBhdm+Po6GxqarZ9x4ZTpxKfv3hGIpEG9A9gMpnqpa3HzWw2RyaVAgAKi/IZDIb6k6rW29P79euXndxiRUUZAMDFxV39K4FA8Ort3eGr8gvyAADe3r7qX8lk8uZNO/v39++wmN6tVs5isQWCpg631dWXZGdn9unTVx0bAICdrb29vWNmpnHd3sfo2hwajfb9nl9Tzp/582h8Y2ODg4PT/HkLR4WNUS8lkzW8IbW1PBMTRutHGAyGWCzq5BYb+Q0AABaT1fwInd7xBFfqjy/j39vtTDHqZqRLuvoSgaDpVd6L0LCA1g/W19d2dbt6zeiSAwBwdnZdvOjzmPmLHj26d/Fy8tb/+8bVxd3Do3dbz2cymSLRv0bAQpHQwsJK45MRBHnrES7HFADQPJQCALy1tjY2ygIANL3z9d+lYrRI2er/ZW5h+Z6JScz8Ra2foP5vGg+j660VFRVcvJQMAKDT6cOGhWxYv51IJL54+aydl3j19hGLxfn5ec2P5OZmu7n2AgBQqFQAgEQiVj/Ob+LX1b391Wtraw8AyHmWpf5VLpc/fvKwwzo9PfuQSKTMzP+pf1WpVGu/+uzSpXPtFKNdVCpVJpMpFG8m6S4qKmhe1Mvdk1dT3b+f/4D+Aep/ZqbmrTuQxsDoktPQUL99x8b9P/+3rLy0sDD/aMIhpVLZ18evnZcMHjzE3s5h5+4tz188q6urjf9tX25u9ozp0QAAVxd3Not96fI5AIBCodgRt5HN5rz1cisra1/ffvG/7SstK5FKpZu3fNWZ3hGHzRkdPj4p6cSFi2efZDza+2Pc//53v69vv3aKaQeNRrOysn78+MGTjEfNYWhf3779lErllavnAQBVVZXHjv/RvGjGjDkKRPHjvl0SiaS4uPDnA99/+PHMgsLXnVmtwTC65PTrN/CLFV9dvXYhes6UmI9m5ORk7tl1wNXVvZ2XkMnkLZt3s1nsT5fMmz1n8uMnD7du3t23r5/6i3ndum3Z2ZmhYQFRsyeGjAi3t3d8t8P25dpNfbx8FnwSNX5iMIfDHRMxsTP7cD9bvqZ//4Bdu7d+sXLR06cZmzfudHRwaqeY9s2e9eGj/91ft36l+J8Wsn0+3r6LF32+f/+e0LCATVu+/Cjm0+a+KJfDjT/4F51GX7g4el7MtMysx2tWfevp4dWZ1RoMvZ+R/frxaq4VvffAt7/pITzjlUvvn6/+YKUT1oWgZ3RtDgRphTHuW8OJnJystV8ub2tpYsI5FovV1lIIczA5mOnb1++XXxLaWgpjg3MwOViys7XHugQIJTjOgSA0YHIgCA2YHAhCAyYHgtCAyYEgNGByIAgNmBwIQgMmB4LQgMmBIDT0PjlMNhno99nexkiJqEytKFhX0S16nxxTa0pVcacuOIHwo6ZEwuLq95lfep8cz/7s6hIJ1lVAXVOeL/Ly1+9LqvQ+OUQSCJ9lffVoOdaFQJ115+8qL3+WlSMV60K6Re+vCVWrKJSc+7XccwDHwp5Ooen914FBUqlUvDJpfZXU3ZfhO4SLdTndZSDJAQDIZaqndxvqq+WC+k7NUNG+mpoaoUDg6uamjdJQauI3SWVSS0vLntxoXl6eEkEIRCKJSCSSSGQymUqlkslkc3Pzbq6ZY05mmpLdfVmW9vrd2qgZTnK0payszMHB4fjx4zNmzMC2klOnTr18+fLLL7/syY2mpqZu3ry5sbFR9Q8CgUCn02k02o0bN3qyEpyDHZsWdXV1s2fPrq2tBQBgHhsAQGho6Ny5c3t4oyEhIQMGDFAHhkgkkkgkIpEokUhgbN4C2xwAAKitrbWwsEhLS7OwsPDyMq7Zj95VVla2YMGC6urq5kdYLFZqamq7LzI6sM0BR44cWbFiBQBgyJAhuIpNamrq4cOHe367Dg4OkyZNap5OUalUpqamyuXynq8Ez4w6Ofn5+QAANpv9xx9/dOLpPa22tra8HJu97YsWLXJwcFD3RxwcHAAAN2/eTExMxKQYfDLS5NTW1k6bNo3P5wMAJk+ejHU5mmEyzmm2fPlyFotFp9OTk5MBAKNGjSovL3/4sOMZsY2E0Y1zysvL7e3tMzIyzMzMXFxcsC4H12JiYg4d+tctrPl8PofDOXDgwMKFC7GrCxeMq81JSEhYvXo1AKB///74jw1W45xmb8UGAMDhcNSzaW/btg2jovDCWJLz/PlzAICFhcWRI0ewrqWzMBzntC8mJkbd5qSkpGBdC2YMPzn19fVTpkxRD2kiIiKwLqcLsB3ntE99SoGNjc2IESPevXeDMTDkcU5hYaGrq+vz589ZLJajoyPW5RgmoVBIJpNLSkpcXFwoFP2+5KZLDLbNOXr06Nq1awEAffr00dPYXL9+/d2RBt4wmUwajWZubh4cHFxQUNCJVxgIA0xORkYGAMDJyenYsWNY19It9fX1lZWVWFfRKebm5unp6eoTl+rq6rAupycYVHIaGxvHjRsnFosBAMHBwViX011hYWExMTFYV9EFAQEBAIClS5deuHAB61p0zkDGOa9evXJ1da2oqKDT6dbW1liXY+zUZ5qrzwbEuhZdMYTkHDt2LCkpKSEhgUAgYF2LNl2/fr2oqEi/mp3WEhMTeTzesmXLsC5EJ/S7t/bgwQMAgLu7e2JiooHFRr/GORpFRUVxudzy8nJ1/9nA6GtyBALB6NGj1SfwDh48GOtydELvxjnvmjt3ro2NTX19/aZNm7CuRcv0r7eWk5Pj6OgokUgoFEr3L/GFesbZs2crKys/+eQTrAvRGj1LzsmTJ5OTk+Pj48lk/Z6tqzP0fZzzFqVSSSQSd+/evXjxYhMTE6zL6S696a3dunULAODp6Xn48GFjiI0BjHPeor5UbsSIEYbxXaAHbY5YLB4/fvyGDRsM4BBNlzQ0NEgkEltbW6wL0YnLly/7+vra2+vrPYZxnZzMzExbW1sajUYkEtXnt0MGo7q6+uOPP/71119tbGywrgUN/CbnzJkzycnJ+/fvp1INYXouFAxsnKNRZWUlg8EgkUhMJhPrWroGv+McLy+v+Ph4o40NAGDgwIFXrlzBugrdsrW1LS8v7+E55bQCp8m5f/8+g8HAugqMmZqaJiQkNB/wNVS1tbXh4eFYV9FlOE1OSkpKTk4O1lXgBZVKnTt3Lm771d00dOjQiRMnYl1Fl5E2bNiAdQ0aCIVCV1dXeO6mmq2trZeXF4FAkEqlBnAk5C03b960tLTUu245fvcQQO968eJFUlKSehISwyCVSkeOHHn37l2sC+kynPbW0tPTCwsLsa4Cd7y8vFxdXe/du2cw33c1NTWLFi3Cugo0cNrmrF+/PigoaNy4cVgXgkdCoVDdyYHvD4Zw2ub85z//ccP03jV4xmQymUzm/fv3L1++jHUt3ZWWlqaeo1jv4LTNgTojNzfX29u7pKTEyckJ61pQmj59+o4dO/TxWxKnbQ4c53SGt7c3AGDPnj3Xrl3DuhY0FArF2LFj9TE2+E3OhQsXnj17hnUV+mH37t2t73WjR8hk8ocffoh1FSjhNDlwnNMlUVFRAIBt27bp1+HjjIyMO3fuYF0FSjhNztixY9VdEajzYmNj9+zZg3UVXXDq1Kmmpiasq0AJp8mB4xwUKBTKwYMHAQC3b9/GupZOGTp06LBhw7CuAiWcJgeOc7qjT58+gwYNUh/2wbMxY8aw2Wysq0AJp8mB45zusLKyevjwIY/Hq6mpwbqWNhUVFf3+++9YV4EeTpMDxznd5+LiQiaTo6OjZTIZ1rVocPv27YaGBqyrQA+nR0LT09Pt7OxcXV2xLkTvvXjxIjc3d8qUKVgX8rasrCwbGxs9vZQav20OHOdoi5eXlzo2cXFxzQ8OHz48MjKyvr4ew8L8/Pz0Nzb4TQ4c52idp6fn999/DwBQ3+6hvLwcw7ukSKVSfbyCujWcTlw2duxYrEswNFOmTFHf36ayspJIJCIIcvHixenTp1taWvZ8MU+fPsW2xes+nF4TevfuXQRBzMzMsC7EoDAYjEGDBjVPXd/U1EQgEIKCgnq+EhKJNHz4cL2eCQynvbVLly7l5uZiXYWhGTly5Fs7hK5fv47JNKI2NjYODg49v10twmlyhgwZ4u7ujnUVBmXatGnqU12USmVzfsrKyo4ePdrzxaxevZrH4/X8drUIp+OcMWPGYF0C3gkbFbUVcpm0s3dU/27d7zk5OUVFRdXV1XV1dUKhUC6XSySSjLuVeaMEOi72X0QiUdlLpKGM3lDWo9vtJCabbG5Ho5l0cDsmfB3PGTNmTFVVFYFAIBKJ6q9GlUrl7e2dmJiIdWk4IhEiV49VV5dInL2YEqES3UpUKpVSqUSUSoVCwejZ+XRUAKiUSvUE7TgkFigEjYpefszgSKt2noavNicwMDAlJUX9s/qdZTKZ8+bNw7ouHBELkNM/lQVH2pra6Nk0S/rl2b2Gi39UjZnb5hEnfOV+zpw5b82x5u7uDnturR3ZVhQxzxHGRtd8gkwt7OlXE6raegK+kuPh4REYGNj8K41Gmz59OqYV4cvj6w3vDTenmeDrr2ao+gziikXK6hKpxqW4+xtER0c3NzvOzs5wYqTWKgrFbFMK1lUYEQqVWFep+XxZ3CWnV69e6jvm0mi06OhorMvBF0SmYlvAflrP4VrShI0KjYtwlxwAwLx586ysrFxcXMaPH491LfgiEiJKJcqdaRAKCrkSQTTvfO7WvjV+rbz4ubi6TCpoVIgaFSolQSHv7OGFdhHH+n5Ho1H/3FqkjbUBjiVVJkaYXDLLlGzjTHP3ZVJoePzKgPQIyuQ8vtGQk86XSZSm9hwCiUKm0rmOJCKZCLR0dMgaaPUuBgQCWYbIpUhNNVJWILx+vNrSnt5vOKf3QH29lBfCXJeT8/hGQ/o5noO3pbWnNY2lN6NVGrOlVDtvK2GdJOue6N75uuGRlm599ew+exAedCE5YqHyXHylikDxCXMjdHBqAt4xzelMc7rUmn03pe7ZA8H4GD2+xArCRGe7+6WvRIc3F5q5WFp7mOt7bJrRmBTH92yUJMbhzUUqOPCGuqJTyWmokV/9i9dnhAuZStJ9ST2NbcWw9bY5sr0YUeDoFD4I5zpOTk2pNOlAhau/fl9N0T4ak2LnY/fbtwVYFwLpjQ6So0TA8T0lLgYdGzUylejQ1+bk3jKsC4H0QwfJSTlU2Wuw4cdGjWFGJzMY/7uu39fHQz2jveQUZAsFjUo6x4hO9zC159w/XwsHPFCH2kvO7TM8cxfzHiwGF2x7m99J0u8LfaEe0GZyCnKENBa99QFEXHmcdSl2XaBIxNf6ms2duAW5YoVc6yvWV7W1vNCwgFu3r2NdSKdcvXYxNCyA36T9D8Zb2kxOXqaAyqLpevP4RKFTCnLweIk8nuXn530wawLWVfScNpNTmCNiWzF6thi8YJoz8jLxfgsNvMl9no11CT1K89k3vDKZmZ2J7o575hdlXLlxsKQsl8Oy9PYaGh7yEZ3OBADcTj92/dYf86K+O/731mpeoZ2NR/DQWYMGvLnW4NzFvY8yz9OojAF+EZbmjjqqDQDAtmLWFRhCcnJyspYu/3DfT4e9+/RVP/LBrAmhIaMXfrI88djhv47/ufKLr3fv+b/GxgZ7e8d5cxaEh7+5jvDa9UuHDu0XCAX/CRo+7f1ZzSsUCAQnTh558CCtsCjf3Nxy2NCQmPmL6HT6wfifjiYcAgCEhgV8unjF9Gmzebyafft35zzLEovFgYFD50Z/7OTk0n61p04lJhz7fdOGuB07NxUXF7q7e8yYFh0RMUE938iZpBMXLiQVFuWbmpp5eHgtXLDcxeXN/Mk/H/j+8pUUhgkjLGyMg/2/btN9/kJS8rnThYWv3d09Q0PC358aRdDSKTCa2xxBo0Iq1sr1AhpU1RQePPwZolAs+yR+zsytZeXPfz60RH3ZCZlEFYn5Z1J2z5z6Tdyme+/5hJw4s7WhsRoAkPbgVNqDk1PHr/ps4SEzU9trNw/pqDwAAIlMqC4WKdu4MMMw0Kg0oVCQmnol8Wjy36euhIaEb9v+bWlpsbrftfX/vhk9esIfh0+PGjV2708tU7mfPJWQkPj7Bx/MSzhydtmS2GvXLx45Gg8A+PijJR/MnGtjY3vj2qPp02YrFIovYhc9zc6IXbnu999OcDjcJUvnl1d0cKyMQqU2NfH3/hi3ZtW3168+HD5sZNyuzTU11QCAS5fP/bB3R0TExBN/XVj/zbaKirKNm9eqX5V09mTS2ROfLV+zb98fNjZ2fx6Nb17hlSvn43Zu7uPlk3DkbMz8RSdOHv1p325tvYGakyPkK0gUXU2L8yTzEolEmRf1nY2Vq52tx4zIb0rLc5+9uA0AIBCJCCKfNO5zF6f3CASCf/9xSiVSWv4cAHAn/bhf3zA/35EMBifQf5K76wAdladGMyEL+br67sADFQAKhWJq5Ad0Op3LNf0wZjGTwbx+4zIAIOnsCRtr27lzPuawOf4DB48f23IHkQ9mzj34S+KI4DB7LX/eAAAJIElEQVQzM/OgoGEhI8IfPkx/d+WZWY9LSoq+XLtpUECQubnF0k9Xsjnc06c7mACeSCTK5fIln6708XmPQCCMHj0eQZCXL3MBAElJJ0JDwt+f+gGXa+rr22/JpysLCl7n5mYDAE7/fWxE8KgRwWEcNmfc2Mn9/AY2rzA55bSf34DPlq8xMzMP8A/8cP7iM0nHRSKRVt5AzcmRiRAKXVd71QqLM50cfZhMU/Wv5mb2FuaO+YVPmp/g7PCma2FCZwMAxJImlUrFqyuxsW65u4Gjg27vS8WxoImaDDk5ah4eXuofCASCvb1jYeFrAEBZWYmrW6/m5/T5p6envhXpg4dpi5fMC48ICg0LOHU6sa6+9t3VPn2aQaFQBg4Y1Lzy/v38nz598u4z39W8ORaLDQAQCJoAAAWFr3183mt5jldfAEDe65cqlaqsrMTVtWU6WC8vH/UPCoXi2bOngwL+07xowIBBCIJUdNT0dZLmhoVAIshlutovK5YIyipexK4LbP1gU1PLH+DdnqhEKlQqETqd1fwIlULXUXlqggYZlWYo54S3jUZr2X1Ko9PFEjEAgM9vdHZuuecXnd4yj+G+n/dcuXL+kwXLBgX8x8bG9sAvP1y9duHd1QoETXK5PDQsoPWDFhadumnCu399gUAglUpptJa/OIPBAACIxSKhUIggCJPZ8sGg//M0iUSCIEj8b/vif9vXem0ikXZGsJqTw+SQlXKxVjbwLjbbwo3aP2LkJ//aIoPbzkvoNCaRSFIoWubvkcq00+a2RSZBGGx8TeOoFQjyr4ZUKBQymW8u7JNKJJYWVgAADocrlba81c0fNaVSef78mRnToyeMj1Q/om4Q3mVhYWliYrJ1y79uMU8moXw/6XQ6AEAiaflACkVCAIC5uSWTySSRSLLW1YrffDBYLBadTh8TMTE4OKz12lo3p92hubfG5JAUMl31VextPRv51b3cBnq4+6v/sVhm1lbt3diQQCCYmdoVFj9tfiT3xV0dlQcAUCkBolDSGHo/VwGFSm39meM38evq/tW5epLxUP2DVCotLil0de0FALCxsXuW+7R5qpB79++of5DJZBKJxMLCqvnX9Huabx/v7u4pFottbe0H9A9Q/7O2tm3uGXYVmUz26u2dk5PV/Ij6Z3c3DwKBYGNjl/OsZVFztW/KkIiba+jr42dpYcVmaecSes0fDksHmkysebKc7hsxdDaCKJLO75HJJFU1hecu7t3146zKqtftv6qf76jM7KtZ2dcBANdvHS4p1+E9QqQCmZVjj061rCOuLu5sFvvS5XPqfv+OuI1sdssta8hk8unTx0pLixEEORj/k1QqHRk6GgAQEhJeV1e7b/8elUr1JOPR2bMn1c+n0+kODk4XLyWXlZc2Njbs2LlpQP8APr9RIpEAABwdnWtreXfv3iwpKQocPGTw4CFxcZuqqiobGxtO//3X4k/nXrh4FvV/ZNKkaTdvXTt9+liToOlJxqN9+3cPCghyd/cAAISGhN9IvXLz1jUAQELi7y9etNwkc+GC5bduXTt/IUmpVGZlPdm05cuVqxYrFNr5YGtODpVO5JiThfUSrWzjLUwGN3ZpApVC/+/P8+J+mJlf9GRG5DoH+w6+kEaNiBk0YMLplLjYdYG5L9MmRiwHAKh0cyVnE0/o6mMIyaFSqevWbcvOzgwNC4iaPTFkRLi9vWPrDtv7U6M+W7Fg1OjACxeTvlyz0dHRGQAwKCBo4SfL09NvjRw1aPuODWtWb1B31QAA69dto1Ao82OmRc+ZMsg/6MMPP6VSqJOmhFZXVwUFDnvPt/8361deu34JALBt63+Dg8M2bflyytRRZ5KOj4mYODVyJur/yNgxkz768NNjx/+YNDl0x46N/fwGfvPN/6kXRc/+aEzExO9/2B4aFnDv/p3FCz8HAKiUSgCAn9+AA/uPZGU9iXw/fNWaJSKhcMvm3WSydjrhbd7L4PH1+lc5ChsPozvjEwBQ8LBs0gJbCzvcnSR+bFdJ0ARrC1stnBV16vSxfft3X7vyQBt1GayM1DoaHQyO0JCCNrvyvf05ConmeUENm1Qo51pScBgbCFfabLlYXJKDG7WuhG/upPlmjvUNlbt+mq1xkQmdI5ZoPlnVzsZjyccH0FarwbfbIhClhp4rgigAACRN+3O8ew+dPX1TWyusya8dPhHen1Qn1q2Pzch4pHHRpEnTFny8tMcrQq+9O08hctWBr/J9Rmre64UgikZ+tcZFcrmUQtHcoyCRKFxOezf06aq6+vK2FsnkUqqmMigUOpuluRcqrJcIq+tnfK7Dk+K6Q4u9NUzU1vJkcs0dGQaDyeW0d2QCE+301tobLZEohOBIq1fZ9WZOGr6DSSSyuZm9VutEQ7s18Csaxs211eIKodY6eTBUL3RwyMJ3CIfNVjZWaD7gZWDKc6oGh3O5VgZ4ABTSuo4P9o2KsqYQpPWlBh6eityavkHMXn6sTjwXgjo3U+G4GBulRFhf1qj7erBR8azabwij3zDc9bMh3OrsCSbvL3MwN1fWl9QjcoOaRlbcKC17WhEQxu4bpHkXIgRp1IU+/Yipli+fCG4cLzFzYFv30vsjpHIxUpPPI6iQsfNszW1wOlEJhFtdGw33HsDqPYD16Gr9q4xKpYrAMGNwrJkkij6dGSkVyPk1QlG9yIRJDBxt2ssP3gIEQgPNfqSAUWYBo8zys4Wvs4TVrwSN1TKqCYlCJ1HoZHzei49KJ4kaZDIJIhMjLFNyLz+W+zgrO1fdXuEDGTb0e2DdfZnuvkwAgEyiFPIRIV8hlyjbOa6KISKJSGMQmRwyk00iUQz/ejWoB2jh2AWVTqTSiWbWcKgAGRF41E+fmFpS4R2yehKZQqQzNHdS9GlwD5mwiLxSnVw0BWlUWSgytdLcmYLJ0Se9/Fi1FTA5PQRRqGQSxNFT80y3MDn6xNHTxMKWci+lButCjMLVhPIRU62IbUx0295VBhA+PbxSV1cpN7ejWzrQifCrT9vEAqSxRvbkRu37yx2tHNq8oAMmRy+VvhK/zhKIhUhDtTFet6tTDDbZxoU+cKQZhdreAQyYHAhCAzb2EIQGTA4EoQGTA0FowORAEBowORCEBkwOBKEBkwNBaPw/Cas1ujzl0ZYAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5174bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'should_continue': {'messages': [AIMessage(content='Continue the workflow', additional_kwargs={}, response_metadata={}, id='abcd1ca5-ad7a-42a9-98ec-7d2d6a64847a')]}}\n",
      "{'update_node': {'counter': 1, 'remaining_steps': -1, 'messages': [HumanMessage(content='Check your counter value, then update it twice, then check its value again, then update it two more times', additional_kwargs={}, response_metadata={}, id='6e2b3ae9-06f9-42d8-b03e-0ebb029a73cd'), AIMessage(content='Continue the workflow', additional_kwargs={}, response_metadata={}, id='abcd1ca5-ad7a-42a9-98ec-7d2d6a64847a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xHMAxZnQvdtDWuUxUIv76HIk', 'function': {'arguments': '{}', 'name': 'update_counter_new'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 80, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByKOTw8VrucpwCphCJZGjhek1OCnq', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='updater_agent', id='run--03a9495b-9a73-4c51-8216-f726fef07c5f-0', tool_calls=[{'name': 'update_counter_new', 'args': {}, 'id': 'call_xHMAxZnQvdtDWuUxUIv76HIk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 11, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Counter updated', name='update_counter_new', id='5f5c012b-be79-43ac-9aae-bb1757a85271', tool_call_id='call_xHMAxZnQvdtDWuUxUIv76HIk'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_64hFqjpdepLwRCkSzfGPJais', 'function': {'arguments': '{}', 'name': 'update_counter_new'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 106, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByKOUUdNCIIxf5jEhHgcdvRJxdvHj', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='updater_agent', id='run--0de71c4d-0b79-46a7-a4f2-bc0ba25faa1b-0', tool_calls=[{'name': 'update_counter_new', 'args': {}, 'id': 'call_64hFqjpdepLwRCkSzfGPJais', 'type': 'tool_call'}], usage_metadata={'input_tokens': 106, 'output_tokens': 11, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Counter updated', name='update_counter_new', id='a37edba9-b778-4384-a71e-7ded3c296d03', tool_call_id='call_64hFqjpdepLwRCkSzfGPJais'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xXdKlIwztF4FiODiJNYvtuni', 'function': {'arguments': '{}', 'name': 'update_counter_new'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 132, 'total_tokens': 143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-ByKOV9DWX6ihwHYQXzHan7t1rct6y', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, name='updater_agent', id='run--9fe7c191-4edc-4e7d-9c89-48b0fc17f43a-0', tool_calls=[{'name': 'update_counter_new', 'args': {}, 'id': 'call_xXdKlIwztF4FiODiJNYvtuni', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 11, 'total_tokens': 143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Counter updated', name='update_counter_new', id='cc266f83-d942-496c-835b-58d1d7ffe0fd', tool_call_id='call_xXdKlIwztF4FiODiJNYvtuni'), AIMessage(content='Sorry, need more steps to process this request.', additional_kwargs={}, response_metadata={}, id='run--32136d82-595e-4516-bc16-d54b1459a209-0')]}}\n",
      "{'should_continue': {'messages': [AIMessage(content='Stop condition met!', additional_kwargs={}, response_metadata={}, id='6ce869e7-aca6-4237-8269-1ab44f3a8417')]}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Check your counter value, then update it twice, then check its value again, then update it two more times\",\n",
    "            }\n",
    "        ],\n",
    "        \"remaining_steps\" : 4,\n",
    "        \"counter\" : 0 \n",
    "    }\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98237fd4",
   "metadata": {},
   "source": [
    "It works. This is interesting not only for the recursion limit fixes, but also because it reminds us that we can actually build very structured and controlled graph flows, by constructing the graph ourselves. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
