{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc11fd7",
   "metadata": {},
   "source": [
    "# ReAct Agents\n",
    "\n",
    "Now we are going to code a ReAct agent. (see also: https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/?h=react).\n",
    "These are a widely used type of agent. \n",
    "ReAct stands for REasoning and ACT agent. \n",
    "Basically this agent has access to tools; he loops through tool nodes, performing tool calls, until he decides there is no need for more tool calling. \n",
    "When that happens, he stops its flows. \n",
    "See the image below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5e838",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../images/react.png\" alt=\"Basic Example of a graph in LangGraph\" style=\"width: 70%;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674b21a",
   "metadata": {},
   "source": [
    "So we will: \n",
    "    - Learn how to create **tools** in LangGraph\n",
    "    - How to create a ReAct Graph\n",
    "    - Work with ToolMessages\n",
    "\n",
    "The code is inside `0.8.10_ReAct_agent.py`.\n",
    "\n",
    "We will use this notebook for further notes and insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39790920",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5676525c",
   "metadata": {},
   "source": [
    "### `Annotated`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924eb406",
   "metadata": {},
   "source": [
    "The `Annotated` type lets you attach **metadata** to a type hint without affecting the actual runtime behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd33b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated #<- provides additional context without affecting the type itself\n",
    "\n",
    "#example: \n",
    "\n",
    "email = Annotated[str, \"This has to be a valid email format!\"]  # we add metadata to our variable\n",
    "\n",
    "print(email.__metadata__)   # allows us to inspect metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080fdbb",
   "metadata": {},
   "source": [
    "### `Sequence`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08331add",
   "metadata": {},
   "source": [
    "The `Sequence` type represents any **ordered, iterable collection** that supports indexing and `len()` — like lists, tuples, or strings.\n",
    "\n",
    "```python\n",
    "from typing import Sequence\n",
    "\n",
    "def total_length(items: Sequence[str]) -> int:\n",
    "    return sum(len(item) for item in items)\n",
    "```\n",
    "- Accepts both `list` and `tuple` (or any sequence-like object).\n",
    "- Ensures items are indexable (`items[0]`), iterable, and have a length (`len(items)`).\n",
    "Read-only: does not guarantee `.append()` or mutability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b015b9f",
   "metadata": {},
   "source": [
    "### 🔁 `add_messages` from `langgraph.graph.message`\n",
    "\n",
    "`add_messages` is a **reducer function** used in LangGraph. A reducer controls **how updates from nodes are merged into the existing state** during graph execution.\n",
    "\n",
    "It is especially useful when working with message histories in an agent.\n",
    "\n",
    "---\n",
    "\n",
    "### Without a reducer (default overwrite)\n",
    "\n",
    "```python\n",
    "state = {\"messages\": [\"Hi!\"]}\n",
    "update = {\"messages\": [\"Nice to meet you!\"]}\n",
    "\n",
    "# result without a reducer:\n",
    "new_state = {\"messages\": [\"Nice to meet you!\"]}\n",
    "```\n",
    "\n",
    "### With `add_messages` reducer (merge behavior)\n",
    "\n",
    "```python\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "state = {\"messages\": [\"Hi!\"]}\n",
    "update = {\"messages\": [\"Nice to meet you!\"]}\n",
    "\n",
    "# result with add_messages:\n",
    "new_state = {\"messages\": [\"Hi!\", \"Nice to meet you!\"]}\n",
    "```\n",
    "The `add_messages` reducer preserves the previous conversation, appending new messages to the existing list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d4066",
   "metadata": {},
   "source": [
    "### 💬 `BaseMessage` in LangChain\n",
    "\n",
    "`BaseMessage` is the **abstract base class** for all messages exchanged in a LangChain conversation. It's part of the `langchain_core.messages` module and defines the common interface for:\n",
    "\n",
    "* Human messages (`HumanMessage`)\n",
    "* AI messages (`AIMessage`)\n",
    "* System messages (`SystemMessage`)\n",
    "* Function or tool messages (e.g., `FunctionMessage`, `ToolMessage`)\n",
    "\n",
    "---\n",
    "\n",
    "### 🧱 Purpose\n",
    "\n",
    "`BaseMessage` ensures that all message types:\n",
    "\n",
    "* Store the actual **content** (usually a string)\n",
    "* Track the **role** (e.g. `\"human\"`, `\"ai\"`, `\"system\"`, etc.)\n",
    "* Optionally include **metadata** and **tool call information**\n",
    "\n",
    "This uniform structure allows messages to be:\n",
    "\n",
    "* Easily parsed by LLMs\n",
    "* Logged and traced across a graph\n",
    "* Passed as part of an agent's state\n",
    "\n",
    "---\n",
    "\n",
    "### 🧾 Example\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hello!\"),\n",
    "    AIMessage(content=\"Hi there! How can I help you today?\")\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Common Subclasses\n",
    "\n",
    "| Class             | Role         | Use case                            |\n",
    "| ----------------- | ------------ | ----------------------------------- |\n",
    "| `HumanMessage`    | `\"human\"`    | User input                          |\n",
    "| `AIMessage`       | `\"ai\"`       | LLM-generated reply                 |\n",
    "| `SystemMessage`   | `\"system\"`   | Instructions or context for the LLM |\n",
    "| `ToolMessage`     | `\"tool\"`     | Output from a tool call             |\n",
    "| `FunctionMessage` | `\"function\"` | Function-calling responses          |\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Notes\n",
    "\n",
    "* You should never instantiate `BaseMessage` directly. Always use its subclasses.\n",
    "* All messages are typically stored in a `messages` list passed to agents or chains.\n",
    "* Useful for creating conversation history in memory or routing logic.\n",
    "\n",
    "Let me know if you want a section about serializing or customizing messages!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf2e55",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a7a69",
   "metadata": {},
   "source": [
    "#### 📌 `Annotated[Sequence[BaseMessage], add_messages]` explained\n",
    "\n",
    "This type annotation is used in LangGraph to define:\n",
    "- A list of LangChain messages (`HumanMessage`, `AIMessage`, etc.)\n",
    "- With `add_messages` as a reducer function to **append** new messages to the existing list during state updates.\n",
    "\n",
    "It allows automatic merging of conversation history as the agent runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104bdf0f",
   "metadata": {},
   "source": [
    "> **Note:** Although `Annotated` is generally used to add metadata like descriptions or constraints, in LangGraph it is also used to attach a function — such as `add_messages`. This function acts as a reducer, meaning it defines how new data should be merged with the existing state. You're not calling the function directly; you're tagging the type with special behavior that LangGraph will use during execution to manage state updates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10527912",
   "metadata": {},
   "source": [
    "#### 📌 `@tool` Decorator and `bind_tools()`\n",
    "\n",
    "When we define tools we need to explicitly use the tool decorator, in order for our language model to know that it can use that function.\n",
    "\n",
    "After defining the tools we give the model access to them by \"binding\" them with `bind_tools()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87404f0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
