{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Ak7ZgyzAZTvR",
      "metadata": {
        "id": "Ak7ZgyzAZTvR"
      },
      "source": [
        "# **OpenAI**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff27fe1",
      "metadata": {
        "id": "8ff27fe1"
      },
      "source": [
        "## OpenAI and Its APIs\n",
        "\n",
        "OpenAI is a leading artificial intelligence research and deployment company whose mission is to ensure that artificial general intelligence (AGI) benefits all of humanity. It is best known for developing state-of-the-art AI models such as GPT (Generative Pre-trained Transformer) for natural language processing, DALL·E for image generation, Whisper for speech recognition, and Codex for code generation.\n",
        "\n",
        "OpenAI provides access to these models via powerful, developer-friendly APIs that allow users to integrate advanced AI capabilities into their applications. These APIs support a wide range of use cases, such as:\n",
        "\n",
        "*  **Natural Language Understanding and Generation**: chatbots, summarization, translation, question answering\n",
        "*  **Image Generation**: text-to-image generation using models like DALL·E\n",
        "*  **Code Completion and Assistance**: intelligent code generation with Codex\n",
        "*  **Speech-to-Text**: transcription and audio processing with Whisper\n",
        "\n",
        "## OpenAI API Access\n",
        "\n",
        "Developers can access these services via the [OpenAI platform](https://platform.openai.com/), where they can obtain [API keys](https://platform.openai.com/api-keys), monitor usage, and manage billing. The APIs can be accessed using Python, JavaScript, or any HTTP client. OpenAI also supports **fine-tuning**, **embeddings**, and **function calling**, allowing for highly customized applications."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfbcc269",
      "metadata": {},
      "source": [
        "## 0. Set Up\n",
        "\n",
        "We need to install some packages, which you can find in the `openAi_requirements.txt` file.\n",
        "\n",
        "Next we need to import some libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "52eba9ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv  # for the API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "74e4a8d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: openai\n",
            "Version: 0.28.0\n",
            "Summary: Python client library for the OpenAI API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: OpenAI\n",
            "Author-email: support@openai.com\n",
            "License: \n",
            "Location: /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages\n",
            "Requires: aiohttp, requests, tqdm\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip show openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0687d7",
      "metadata": {},
      "source": [
        "Next we need to [get our OpenAI key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key) and save it in our `.env` file, so we can load it with `load_dotenv()`. \n",
        "\n",
        "We should save it in the following format:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e728eb",
      "metadata": {},
      "source": [
        "```\n",
        "OPENAI_API_KEY = \"your_key_here\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e5bf408c",
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # load key "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d5461a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the key\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26c2d32f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x74ac235e6cf0> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"id\": \"gpt-4-0613\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1686588896,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1687882411,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677610602,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2025-06-03\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1748908498,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-nano-2025-04-14\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744321025,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-nano\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744321707,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-image-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1745517030,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2025-06-03\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1748907838,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634301,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634615,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692901427,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1694122472,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-3\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698785189,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-2\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698798177,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-1106-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698957206,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698959748,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699046015,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053241,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053533,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-3-small\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1705948997,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-3-large\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1705953180,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0125-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706037612,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706037777,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-0125\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1706048358,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1712361441,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-turbo-2024-04-09\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1712601677,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1715367049,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-05-13\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1715368132,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-2024-07-18\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1721172717,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1721172741,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-08-06\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1722814719,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"chatgpt-4o-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1723515131,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-preview-2024-09-12\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648865,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648897,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-mini-2024-09-12\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725648979,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1725649008,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2024-10-01\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727131766,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2024-10-01\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727389042,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727460443,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1727659998,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"omni-moderation-latest\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1731689265,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"omni-moderation-2024-09-26\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1732734466,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-realtime-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1733945430,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-audio-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734034239,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-realtime-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734112601,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-audio-preview-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734115920,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-2024-12-17\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734326976,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734375816,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-realtime-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734387380,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-audio-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1734387424,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o3-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1737146383,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o3-mini-2025-01-31\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1738010200,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-2024-11-20\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1739331543,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.5-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1740623059,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.5-preview-2025-02-27\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1740623304,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-search-preview-2025-03-11\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741388170,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-search-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741388720,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-search-preview-2025-03-11\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741390858,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-search-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1741391161,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-transcribe\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742068463,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-transcribe\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742068596,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-pro-2025-03-19\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742251504,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"o1-pro\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742251791,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4o-mini-tts\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1742403959,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-2025-04-14\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744315746,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744316542,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-mini-2025-04-14\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744317547,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4.1-mini\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1744318173,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-16k\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1683758102,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1681940951,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"whisper-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677532384,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-ada-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1671217299,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    }\n",
              "  ]\n",
              "}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# list the models\n",
        "\n",
        "openai.Model.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f28c1064",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>object</th>\n",
              "      <th>created</th>\n",
              "      <th>owned_by</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>model</td>\n",
              "      <td>1686588896</td>\n",
              "      <td>openai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-4</td>\n",
              "      <td>model</td>\n",
              "      <td>1687882411</td>\n",
              "      <td>openai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>model</td>\n",
              "      <td>1677610602</td>\n",
              "      <td>openai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gpt-4o-audio-preview-2025-06-03</td>\n",
              "      <td>model</td>\n",
              "      <td>1748908498</td>\n",
              "      <td>system</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gpt-4.1-nano-2025-04-14</td>\n",
              "      <td>model</td>\n",
              "      <td>1744321025</td>\n",
              "      <td>system</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>gpt-4.1-mini</td>\n",
              "      <td>model</td>\n",
              "      <td>1744318173</td>\n",
              "      <td>system</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>gpt-3.5-turbo-16k</td>\n",
              "      <td>model</td>\n",
              "      <td>1683758102</td>\n",
              "      <td>openai-internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>tts-1</td>\n",
              "      <td>model</td>\n",
              "      <td>1681940951</td>\n",
              "      <td>openai-internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>whisper-1</td>\n",
              "      <td>model</td>\n",
              "      <td>1677532384</td>\n",
              "      <td>openai-internal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>text-embedding-ada-002</td>\n",
              "      <td>model</td>\n",
              "      <td>1671217299</td>\n",
              "      <td>openai-internal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id object     created         owned_by\n",
              "0                        gpt-4-0613  model  1686588896           openai\n",
              "1                             gpt-4  model  1687882411           openai\n",
              "2                     gpt-3.5-turbo  model  1677610602           openai\n",
              "3   gpt-4o-audio-preview-2025-06-03  model  1748908498           system\n",
              "4           gpt-4.1-nano-2025-04-14  model  1744321025           system\n",
              "..                              ...    ...         ...              ...\n",
              "67                     gpt-4.1-mini  model  1744318173           system\n",
              "68                gpt-3.5-turbo-16k  model  1683758102  openai-internal\n",
              "69                            tts-1  model  1681940951  openai-internal\n",
              "70                        whisper-1  model  1677532384  openai-internal\n",
              "71           text-embedding-ada-002  model  1671217299  openai-internal\n",
              "\n",
              "[72 rows x 4 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# turn model's \"data\" into dataframe to inspect\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(openai.Model.list()['data'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34d1e3b2",
      "metadata": {},
      "source": [
        "## 1. Hands on OpenAI - ChatCompletion API and Completion API\n",
        "\n",
        "We have two kinds of API in OpenAI: \n",
        "- **Chat Completion APIs**\n",
        "- **Completion APIs**\n",
        "\n",
        "Both are very easy to use. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381b1f59",
      "metadata": {},
      "source": [
        "### 1.1 ChatCompletion API\n",
        "\n",
        "Let's say we want to use GPT-Trubo 3.5 for chat completion: we can use the `ChatCompletion` class methods, but we need to follow a specific format. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ed66a6b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-BhXzaDKAUnQg23dRQ0hCEA7p6jGqZ\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1749718470,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Hello! I'm here and ready to help. How can I assist you today?\",\n",
            "        \"refusal\": null,\n",
            "        \"annotations\": []\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 23,\n",
            "    \"completion_tokens\": 17,\n",
            "    \"total_tokens\": 40,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  },\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Hello, How are you?\"\n",
        "\n",
        "result = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # first we choose the model\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da1f118",
      "metadata": {},
      "source": [
        "To interact with OpenAI's Chat API using the `openai.ChatCompletion.create()` method, you need to structure your request properly. First, specify the model you want to use (e.g., `\"gpt-3.5-turbo\"`). Then, define the conversation history through the `messages` parameter — a list of dictionaries where each message includes a `role` (`\"system\"`, `\"user\"`, or `\"assistant\"`) and its corresponding `content`. The `\"system\"` message sets the behavior or context of the assistant, while the `\"user\"` message contains the actual prompt or question. This structured format allows the model to maintain context and respond coherently in a conversational style.\n",
        "\n",
        "We can see that the result is not actually parsed, but in a dictionary form. If we want the actual response, we can select it by doing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a25e4b10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I'm here and ready to help. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "print(result[\"choices\"][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cd53a0c",
      "metadata": {},
      "source": [
        "#### 1.1.2 Prompting With More Context\n",
        "\n",
        "In a chat completion model, we can actually pass multiple prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "53036330",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, but I don't have the ability to access personal information about you. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "prompt1 = \"Hello How are you?\"\n",
        "prompt2 = \"I am 25 years old & I am an AI Researcher\"\n",
        "prompt3 = \"Tell me about me\"\n",
        "\n",
        "result = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt1},\n",
        "        {\"role\": \"user\", \"content\": prompt2},\n",
        "        {\"role\": \"user\", \"content\": prompt3},\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(result[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d679dd9",
      "metadata": {},
      "source": [
        "Well, it looks like our model hasn't captured what we told him... why is that? To fix this we need to look into the `\"assistant\"` role.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9203bfa",
      "metadata": {},
      "source": [
        "#### 1.1.3 The `assistant` Role\n",
        "\n",
        "The `\"assistant\"` role in the `ChatCompletion.create()` method represents the model's responses in the conversation. Including assistant messages helps maintain the flow of dialogue and provides the model with a history of what it has already said. This is crucial for generating coherent and contextually accurate replies. By alternating between `\"user\"` and `\"assistant\"` messages, you allow the model to build a logical understanding of the conversation and respond appropriately based on prior interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "32fce451",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As an AI assistant, I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am programmed to respect user privacy and confidentiality. How can I assist you further today?\n"
          ]
        }
      ],
      "source": [
        "prompt1 = \"Hello How are you?\"\n",
        "prompt2 = \"I am 25 years old & I am an AI Researcher\"\n",
        "prompt3 = \"Tell me about me\"\n",
        "\n",
        "result = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"I'm great! How can I help you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"I am 25 years old & I am an AI Researcher.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"That's impressive! Working in AI is very exciting.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Tell me about me.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(result[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1a2978",
      "metadata": {},
      "source": [
        "> **Note:** When using the `ChatCompletion.create()` method, it's important to structure your messages as a real conversation by [alternating between `\"user\"` and `\"assistant\"` roles](https://community.make.com/t/what-is-the-difference-between-system-user-and-assistant-roles-in-chatgpt/36160). If you stack multiple `\"user\"` messages without including the assistant's responses, the model won't be able to process the context properly. This can result in generic answers, such as stating it doesn't have personal information, even if you provided it earlier. To maintain coherent dialogue and context awareness, always simulate a back-and-forth interaction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71528935",
      "metadata": {},
      "source": [
        "Although it might seem redundant to \"tell the assistant\" something and then ask about it, this structure is essential for real-world applications of the `ChatCompletion.create()` method. The key is not to think of it as quizzing the assistant on what you just said — instead, you're building up context that the assistant can use to reason, generate, or respond meaningfully. \n",
        "\n",
        "For example, in a chatbot or virtual assistant, the user might first provide travel details like \"I'm looking for flights from Rome to Paris next week,\" and the assistant will follow up with a relevant question. Later, when more information is given, the assistant can suggest results or take action. \n",
        "\n",
        "Another use case is when you provide background information (e.g., your age, job, preferences) and then ask the assistant to generate a bio or personalized message — it's not about repeating facts, but about synthesizing them into something new. \n",
        "\n",
        "In reasoning tasks, you can guide the assistant step-by-step (e.g., assigning values to variables), and finally ask it to compute or deduce something based on prior steps. Including both `\"user\"` and `\"assistant\"` messages creates a history that allows the model to maintain context and behave intelligently, even in multi-turn conversations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8e848d4",
      "metadata": {},
      "source": [
        "#### 1.1.4 Tweaking Parameters\n",
        "\n",
        "* `max_tokens`: number of maximum tokens the model will generate (does not include input tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d0fb9762",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is a versatile and widely used programming language known for its simplicity and readability. It is popular for various applications, such as\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is Python?\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    max_tokens = 25\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de82d65",
      "metadata": {},
      "source": [
        "* `temperature`: parameter that allows the model to weight more less probable completion characters, meaning that it will have more \"freedom of choice\" in generating the next token, as it will not always choose the one with maximum probability.\n",
        "\n",
        "We call it temperature because it resembles the thermodinamic temperature in the Softmax function, $\\text{softmax}(x)_i = \\exp(\\frac{y_i}{T}) / \\exp(\\frac{\\sum_j y_j}{T}))$. So if $T$ is very big, the model choose aribitrarily between the generated next completion tokens, while if $T=0$ it only chooses the one with maximum probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "097cc435",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is a high-level, versatile programming language known for its simplicity and readability. It is widely used in various fields such as web development, data science, artificial intelligence, and more. Python supports multiple programming paradigms and has a large standard library that makes it easy to implement various tasks.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is Python?\"\n",
        "\n",
        "response =openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0.6\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "50b7ebb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is a high-level, general-purpose programming language known for its simplicity and readability. It is widely used in various fields, such as development, data analysis, artificial intelligence, scientific computing, and web development. Python's design emphasizes code readability and clarity, making it a popular language among beginners and experienced programmers alike. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is Python?\"\n",
        "\n",
        "response =openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 1.6\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446f278e",
      "metadata": {},
      "source": [
        "* `n`: number of responses the model outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1db7c616",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python is a high-level, interpreted programming language known for its simplicity and readability. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is widely used for web development, data analysis, artificial intelligence, scientific computing, and many other applications.\n",
            "Python is a popular high-level programming language known for its simplicity and readability. It is widely used for various applications such as web development, data analysis, artificial intelligence, scientific computing, and automation. Python supports multiple programming paradigms and has a large standard library that provides ready-to-use modules and functions for different tasks.\n",
            "Python is a high-level, interpreted programming language known for its simplicity and readability. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is widely used for web development, data analysis, artificial intelligence, scientific computing, automation, and more. It has a large standard library and a vibrant community that contributes to its ecosystem through packages and frameworks.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is Python?\"\n",
        "\n",
        "response =openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0.6,\n",
        "    n = 3\n",
        ")\n",
        "\n",
        "print(f\"{response['choices'][0]['message']['content']}\\n{response['choices'][1]['message']['content']}\\n{response['choices'][2]['message']['content']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9018403b",
      "metadata": {},
      "source": [
        "Apart from just text generation, we can do any LLM task, for example sentiment analysis, code writing and so on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "64887d1f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! Here's a simple Python code to add two numbers:\n",
            "\n",
            "```python\n",
            "num1 = 5\n",
            "num2 = 10\n",
            "\n",
            "sum = num1 + num2\n",
            "\n",
            "print(\"The sum of\", num1, \"and\", num2, \"is:\", sum)\n",
            "```\n",
            "\n",
            "You can replace `num1` and `num2` with any numbers you want to add together.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Give me a Python code to add 2 numbers\"\n",
        "\n",
        "response =openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0.6,\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbb73a5",
      "metadata": {},
      "source": [
        "### 1.2 Completion APIs\n",
        "\n",
        "OpenAI provides two main APIs for text generation: `Completion` and `ChatCompletion`. While both can generate text, they differ in structure and use cases. `Completion` is used with older models like GPT-3 and expects a single plain-text prompt. On the other hand, `ChatCompletion` is designed for newer models like GPT-3.5 and GPT-4, and supports multi-turn conversations with structured messages that include roles like `system`, `user`, and `assistant`. For building chatbots or conversational agents, `ChatCompletion` is the recommended approach.\n",
        "\n",
        "| Feature                 | `Completion`                              | `ChatCompletion`                                           |\n",
        "| ----------------------- | ----------------------------------------- | ---------------------------------------------------------- |\n",
        "| **Supported Models**    | GPT-3 (`text-davinci-003`, `curie`, etc.) | GPT-3.5, GPT-4 (`gpt-3.5-turbo`, `gpt-4`, etc.)            |\n",
        "| **Input Format**        | Plain prompt (`prompt=\"...\"`)             | Structured messages (`messages=[...]`)                     |\n",
        "| **Interaction Style**   | Single-shot completions                   | Multi-turn chat with roles (`system`, `user`, `assistant`) |\n",
        "| **Context Handling**    | No role or turn distinction               | Tracks full conversation history                           |\n",
        "| **Best Use Cases**      | Simple completions or prompts             | Conversational agents, chatbots, assistants                |\n",
        "| **System Instructions** | Not supported                             | Supported via `system` role                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c237c537",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-BhYGiYD7CTqOwm7uZ0QmAFPB4467v\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1749719532,\n",
            "  \"model\": \"babbage:2023-07-21-v2\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \" and how does Python works? Python\\n\\nWhat is Python? Python is a programming\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"length\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 3,\n",
            "    \"completion_tokens\": 16,\n",
            "    \"total_tokens\": 19\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is Python\"\n",
        "response = openai.Completion.create(\n",
        "    model = \"babbage-002\",\n",
        "    prompt = prompt\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e01f34",
      "metadata": {},
      "source": [
        "## 2. Function Calling in OpenAI\n",
        "\n",
        "[Function calling](https://platform.openai.com/docs/guides/function-calling?api-mode=responses) provides a powerful and flexible way for OpenAI models to interface with your code or external services.\n",
        "\n",
        "More specifically, function calling enables models like gpt-4 or gpt-3.5-turbo to return structured data (e.g., JSON) that can be used to trigger predefined functions in your code. Instead of just responding in plain text, the model can suggest calling a specific function with specific arguments.\n",
        "\n",
        "If you are familiar with *tool calling*, we can say that function calling is the \"older\" and less general version of tool calling, since the model is allowed to interact only with functions. In a sense, they overlap, but tools have a broader scope than just function calling.\n",
        "\n",
        "### boh\n",
        "\n",
        "Let's see an example of function calling at work. I accessed the [RapidAPI](https://rapidapi.com/MeteosourceWeather/api/ai-weather-by-meteosource/playground/apiendpoint_051aea00-95fb-437c-944c-06dd8d4049d8) in order to get the free plan of the [AI weather](https://rapidapi.com/MeteosourceWeather/api/ai-weather-by-meteosource) API by meteosource.\n",
        "\n",
        "On the page we can find the following code (below code snippet - python):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8700fa8",
      "metadata": {},
      "source": [
        "```python\n",
        "import http.client\n",
        "\n",
        "conn = http.client.HTTPSConnection(\"ai-weather-by-meteosource.p.rapidapi.com\")\n",
        "\n",
        "headers = {\n",
        "    'x-rapidapi-key': \"06d2d29013msh6c0e9656309d413p150efdjsn294c8f9639bb\",\n",
        "    'x-rapidapi-host': \"ai-weather-by-meteosource.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "conn.request(\"GET\", \"/time_machine?lat=37.81021&lon=-122.42282&date=2021-08-24&units=auto\", headers=headers)\n",
        "\n",
        "res = conn.getresponse()\n",
        "data = res.read()\n",
        "\n",
        "print(data.decode(\"utf-8\"))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3eda671",
      "metadata": {},
      "source": [
        "With the help of this we can write a function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e76114c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "\n",
        "import requests\n",
        "def get_current_weather(location):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "\n",
        "    url = \"https://ai-weather-by-meteosource.p.rapidapi.com/find_places\"\n",
        "\n",
        "    querystring = {\"text\":location}\n",
        "\n",
        "    headers = {\n",
        "      'x-rapidapi-key': \"156877d1e1msh6806b57dfec44b9p1bd2c8jsn796f2ff15790\",\n",
        "      'x-rapidapi-host': \"ai-weather-by-meteosource.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers, params=querystring)\n",
        "\n",
        "    print(response.json())\n",
        "  \n",
        "    return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9ffabc0b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'Bologna', 'place_id': 'bologna', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Bologna', 'country': 'Italy', 'lat': '44.49381N', 'lon': '11.33875E', 'timezone': 'Europe/Rome', 'type': 'settlement'}, {'name': 'Bologna', 'place_id': 'bologna-8971140', 'adm_area1': 'Piedmont', 'adm_area2': 'Provincia di Asti', 'country': 'Italy', 'lat': '44.80098N', 'lon': '8.2688E', 'timezone': 'Europe/Rome', 'type': 'settlement'}, {'name': 'Bologna', 'place_id': 'bologna-8977649', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Provincia di Ferrara', 'country': 'Italy', 'lat': '44.89688N', 'lon': '11.98523E', 'timezone': 'Europe/Rome', 'type': 'settlement'}, {'name': 'Bologna', 'place_id': 'bologna-377261', 'adm_area1': 'Central Equatoria', 'adm_area2': None, 'country': 'Republic of South Sudan', 'lat': '5.59644N', 'lon': '31.45129E', 'timezone': 'Africa/Juba', 'type': 'settlement'}, {'name': 'Imola', 'place_id': 'imola', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Bologna', 'country': 'Italy', 'lat': '44.35916N', 'lon': '11.7132E', 'timezone': 'Europe/Rome', 'type': 'settlement'}, {'name': 'Casalecchio di Reno', 'place_id': 'casalecchio-di-reno', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Bologna', 'country': 'Italy', 'lat': '44.47563N', 'lon': '11.27495E', 'timezone': 'Europe/Rome', 'type': 'settlement'}, {'name': 'Savena', 'place_id': 'savena', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Bologna', 'country': 'Italy', 'lat': '44.46933N', 'lon': '11.37864E', 'timezone': 'Europe/Rome', 'type': 'administrative_area'}, {'name': 'Navile', 'place_id': 'navile', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Bologna', 'country': 'Italy', 'lat': '44.53166N', 'lon': '11.34647E', 'timezone': 'Europe/Rome', 'type': 'administrative_area'}, {'name': 'San Lazzaro di Savena', 'place_id': 'san-lazzaro-di-savena', 'adm_area1': 'Emilia-Romagna', 'adm_area2': 'Bologna', 'country': 'Italy', 'lat': '44.46777N', 'lon': '11.41401E', 'timezone': 'Europe/Rome', 'type': 'administrative_area'}]\n"
          ]
        }
      ],
      "source": [
        "# we can call this function as usual...\n",
        "response = get_current_weather(\"Bologna\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2f9917f3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'Bologna',\n",
              "  'place_id': 'bologna',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Bologna',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.49381N',\n",
              "  'lon': '11.33875E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'settlement'},\n",
              " {'name': 'Bologna',\n",
              "  'place_id': 'bologna-8971140',\n",
              "  'adm_area1': 'Piedmont',\n",
              "  'adm_area2': 'Provincia di Asti',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.80098N',\n",
              "  'lon': '8.2688E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'settlement'},\n",
              " {'name': 'Bologna',\n",
              "  'place_id': 'bologna-8977649',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Provincia di Ferrara',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.89688N',\n",
              "  'lon': '11.98523E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'settlement'},\n",
              " {'name': 'Bologna',\n",
              "  'place_id': 'bologna-377261',\n",
              "  'adm_area1': 'Central Equatoria',\n",
              "  'adm_area2': None,\n",
              "  'country': 'Republic of South Sudan',\n",
              "  'lat': '5.59644N',\n",
              "  'lon': '31.45129E',\n",
              "  'timezone': 'Africa/Juba',\n",
              "  'type': 'settlement'},\n",
              " {'name': 'Imola',\n",
              "  'place_id': 'imola',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Bologna',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.35916N',\n",
              "  'lon': '11.7132E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'settlement'},\n",
              " {'name': 'Casalecchio di Reno',\n",
              "  'place_id': 'casalecchio-di-reno',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Bologna',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.47563N',\n",
              "  'lon': '11.27495E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'settlement'},\n",
              " {'name': 'Savena',\n",
              "  'place_id': 'savena',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Bologna',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.46933N',\n",
              "  'lon': '11.37864E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'administrative_area'},\n",
              " {'name': 'Navile',\n",
              "  'place_id': 'navile',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Bologna',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.53166N',\n",
              "  'lon': '11.34647E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'administrative_area'},\n",
              " {'name': 'San Lazzaro di Savena',\n",
              "  'place_id': 'san-lazzaro-di-savena',\n",
              "  'adm_area1': 'Emilia-Romagna',\n",
              "  'adm_area2': 'Bologna',\n",
              "  'country': 'Italy',\n",
              "  'lat': '44.46777N',\n",
              "  'lon': '11.41401E',\n",
              "  'timezone': 'Europe/Rome',\n",
              "  'type': 'administrative_area'}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2495d22c",
      "metadata": {},
      "source": [
        "The interesting thing is that our LLM can use it! \n",
        "\n",
        "We need to follow a [specific function format](https://platform.openai.com/docs/guides/function-calling#defining-functions) to pass functions to our model - be careful, in the past we would have constructed a `function` dictionary directly, but now this format is deprecated -> we must use the `tools` syntax and specify `function` as the `type`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "30faac80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: openai 1.86.0\n",
            "Uninstalling openai-1.86.0:\n",
            "  Would remove:\n",
            "    /home/matteo/miniconda3/envs/openAI/bin/openai\n",
            "    /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages/openai-1.86.0.dist-info/*\n",
            "    /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages/openai/*\n",
            "Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: openai in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (1.86.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/matteo/.local/lib/python3.10/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall openai\n",
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "5e9e7e46",
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'OpenAI' from 'openai' (/home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages/openai/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m tools \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# This should always be \"function\" when defining a function tool\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# If True, only allows exactly the parameters in the schema; False allows extra args\u001b[39;00m\n\u001b[1;32m     21\u001b[0m }]\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/home/matteo/miniconda3/envs/openAI/lib/python3.10/site-packages/openai/__init__.py)"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "tools = [{\n",
        "    \"type\": \"function\",  # This should always be \"function\" when defining a function tool\n",
        "    \"function\": {\n",
        "    \"name\": \"get_current_weather\",  # Unique name of the function to be called by the model\n",
        "    \"description\": \"Get current weather in a given location\",  # Description helps the model decide when to use this tool\n",
        "    \"parameters\": {  # JSON Schema defining the structure of the input the function expects\n",
        "        \"type\": \"object\",  # The top-level input is a JSON object (i.e., a dictionary)\n",
        "        \"properties\": {  # Defines the fields that this object can have\n",
        "            \"location\": {\n",
        "                \"type\": \"string\",  # The value for \"location\" must be a string\n",
        "                \"description\": \"The city and state, e.g. San Francisco, CA\",  # Helps the model understand what to pass\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"location\"],  # \"location\" is a mandatory parameter; the model must provide it\n",
        "    }\n",
        "    },\n",
        "    \"strict\": True  # If True, only allows exactly the parameters in the schema; False allows extra args\n",
        "}]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0796d5d5",
      "metadata": {},
      "source": [
        "Now, our model can use this function tool if needed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "b5879b62",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages= input_messages,\n",
        "    tools=tools    \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "4fdda765",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-BhZKAtkQecmHnQXPeAIGwpH1MMiF7 at 0x74ac08a7ffb0> JSON: {\n",
              "  \"id\": \"chatcmpl-BhZKAtkQecmHnQXPeAIGwpH1MMiF7\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1749723590,\n",
              "  \"model\": \"gpt-3.5-turbo-0125\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": null,\n",
              "        \"tool_calls\": [\n",
              "          {\n",
              "            \"id\": \"call_CheRFUB2G7oqO4JsnWSJ5SH8\",\n",
              "            \"type\": \"function\",\n",
              "            \"function\": {\n",
              "              \"name\": \"get_current_weather\",\n",
              "              \"arguments\": \"{\\\"location\\\":\\\"Paris\\\"}\"\n",
              "            }\n",
              "          }\n",
              "        ],\n",
              "        \"refusal\": null,\n",
              "        \"annotations\": []\n",
              "      },\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"tool_calls\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 71,\n",
              "    \"completion_tokens\": 15,\n",
              "    \"total_tokens\": 86,\n",
              "    \"prompt_tokens_details\": {\n",
              "      \"cached_tokens\": 0,\n",
              "      \"audio_tokens\": 0\n",
              "    },\n",
              "    \"completion_tokens_details\": {\n",
              "      \"reasoning_tokens\": 0,\n",
              "      \"audio_tokens\": 0,\n",
              "      \"accepted_prediction_tokens\": 0,\n",
              "      \"rejected_prediction_tokens\": 0\n",
              "    }\n",
              "  },\n",
              "  \"service_tier\": \"default\",\n",
              "  \"system_fingerprint\": null\n",
              "}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "d633cd05",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x74ac08cfeca0> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": null,\n",
              "  \"tool_calls\": [\n",
              "    {\n",
              "      \"id\": \"call_CheRFUB2G7oqO4JsnWSJ5SH8\",\n",
              "      \"type\": \"function\",\n",
              "      \"function\": {\n",
              "        \"name\": \"get_current_weather\",\n",
              "        \"arguments\": \"{\\\"location\\\":\\\"Paris\\\"}\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"refusal\": null,\n",
              "  \"annotations\": []\n",
              "}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the assistant's message\n",
        "message = response[\"choices\"][0][\"message\"]\n",
        "message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e4f6a4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<OpenAIObject id=call_CheRFUB2G7oqO4JsnWSJ5SH8 at 0x74ac08cfc630> JSON: {\n",
              "   \"id\": \"call_CheRFUB2G7oqO4JsnWSJ5SH8\",\n",
              "   \"type\": \"function\",\n",
              "   \"function\": {\n",
              "     \"name\": \"get_current_weather\",\n",
              "     \"arguments\": \"{\\\"location\\\":\\\"Paris\\\"}\"\n",
              "   }\n",
              " }]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message['tool_calls']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06270afc",
      "metadata": {},
      "source": [
        "We can see that the response is a **tool call**, not an actual chat message!\n",
        "\n",
        "This means we are using the LLM within an **AI agent framework**. In this setup, the LLM acts as the \"brain\" of the agent. First, it performs a **thought step**, where it reasons about the task. Then it takes an **action step** by choosing to call a function — in this case, our `get_current_weather` tool.\n",
        "\n",
        "However, the workflow doesn't end there. After the function is called and the tool returns a result, the agent must process this new information and generate a final response. This is known as the **observation step**.\n",
        "\n",
        "So yes — at this point, you need to pass the **tool's result back to the model** as a new message (from a `tool` role), so it can continue the reasoning and generate the final answer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "1d1212ac",
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "output",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/openai/openai_object.py:59\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[0;31mKeyError\u001b[0m: 'output'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tool_call \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m args \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39marguments)\n\u001b[1;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m get_current_weather(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "File \u001b[0;32m~/miniconda3/envs/openAI/lib/python3.10/site-packages/openai/openai_object.py:61\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[k]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;241m*\u001b[39merr\u001b[38;5;241m.\u001b[39margs)\n",
            "\u001b[0;31mAttributeError\u001b[0m: output"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "tool_call = response.output[0]\n",
        "args = json.loads(tool_call.arguments)\n",
        "\n",
        "result = get_current_weather(args[\"location\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c5f4c9",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "openAI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
